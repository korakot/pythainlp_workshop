{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "workshop_notebook_1-pythatnlp_getting_started.ipynb.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/korakot/pythainlp_workshop/blob/master/notebooks/workshop_notebook_1-pythatnlp_getting_started.ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AT0-j9pdCCc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "7f6c622a-3699-42e8-e25a-9c229a9d6f10"
      },
      "source": [
        "!pip install --upgrade --pre pythainlp "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pythainlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cb/14/b80930a2cc09ed6b5f8a22da9be6ece56939839ae66d921d9c7123034ba0/pythainlp-2.1.4-py3-none-any.whl (11.1MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 11.1MB 2.9MB/s \n",
            "\u001b[?25hCollecting nltk>=3.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.5MB 37.2MB/s \n",
            "\u001b[?25hCollecting tinydb>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/22/11/c3adfc1b367d1955461f82a4a0a8ffffd37b193e98f2fe89338cdd4a8a6a/tinydb-3.15.2-py2.py3-none-any.whl\n",
            "Collecting requests>=2.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/70/1935c770cb3be6e3a8b78ced23d7e0f3b187f5cbfab4749523ed65d7c9b1/requests-2.23.0-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 61kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm>=4.1 in /usr/local/lib/python3.6/dist-packages (from pythainlp) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: dill>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from pythainlp) (0.3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.3->pythainlp) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (2019.11.28)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-cp36-none-any.whl size=1449904 sha256=adc911e14eef9172e8734a261aec81be70b4f95c0bf169b5c26694b081fba00f\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
            "Successfully built nltk\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.21.0, but you'll have requests 2.23.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: nltk, tinydb, requests, pythainlp\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Found existing installation: requests 2.21.0\n",
            "    Uninstalling requests-2.21.0:\n",
            "      Successfully uninstalled requests-2.21.0\n",
            "Successfully installed nltk-3.4.5 pythainlp-2.1.4 requests-2.23.0 tinydb-3.15.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIRogXgddCCh",
        "colab_type": "text"
      },
      "source": [
        "# Workshop Notebook 1: Getting started with PyThaiNLP üòÜ\n",
        "\n",
        "\n",
        "Updated: 31 October 2019"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRhCNHVndCCi",
        "colab_type": "text"
      },
      "source": [
        "## Header\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBauTJuNdCCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import Set, List\n",
        "from functools import reduce\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": false,
        "id": "TZdgP7sPdCCl",
        "colab_type": "text"
      },
      "source": [
        "## 1. Word Tokenization\n",
        "\n",
        "Word Tokenization is a process to determin word boundaries in a text or sentence.\n",
        "\n",
        "\n",
        "Given a sentence, the tokenizer then read the sentence and return a list of words (i.e. tokens).\n",
        "\n",
        "```python\n",
        "\n",
        "    definition: Tokenizer(str) -> List[str]\n",
        "    \n",
        "    \n",
        "    \n",
        "    Tokenizer(str:\"‡πÄ‡∏ò‡∏≠‡∏Ñ‡∏∑‡∏≠ My Ambulance ‡∏Ç‡∏≠‡∏á‡∏â‡∏±‡∏ô\")  -> List[\"‡πÄ‡∏ò‡∏≠\", \"‡∏Ñ‡∏∑‡∏≠\", \"My\", \"Ambulance\", \"‡∏Ç‡∏≠‡∏á\", \"‡∏â‡∏±‡∏ô\"]\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": false,
        "id": "TpJpggrddCCm",
        "colab_type": "text"
      },
      "source": [
        "### Dictionary-based tokenizer\n",
        "\n",
        "\n",
        "Dictionary-based tokenizer is an alogirithm the read through the sentence character by character.  If it found sequences of characters match with a vocabulary in the pre-defined dictionary, it maps sequences of characters as a token.\n",
        "https://www.cs.ait.ac.th/~mdailey/papers/Choochart-Wordseg.pdf\n",
        "\n",
        "\n",
        "```python\n",
        "\n",
        "dictionary = Set[\"‡∏â‡∏±‡∏ô\", \"‡∏ä‡∏≠‡∏ö\", \"‡∏£‡∏ñ‡πÑ‡∏ü\", \"‡∏£‡∏ñ\", \"‡∏£‡∏î\", \"‡∏ô‡πà‡∏≥\", \"‡∏ï‡πâ‡∏ô\", \"‡πÑ‡∏°‡πâ\", \"‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ\", \" \"]\n",
        "\n",
        "\n",
        "Dictionary_Tokenizer(dictionary:Set[str])\n",
        "\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCU16osIdCCn",
        "colab_type": "text"
      },
      "source": [
        "#### 1.1 Longest matching (LM)\n",
        "\n",
        "Longest matching is an algorithm to split words from a sentence by considering logest vocab first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_79P-TYdCCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dictionary = set([\"‡∏â‡∏±‡∏ô\", \"‡∏ä‡∏≠‡∏ö\", \"‡∏£‡∏ñ‡πÑ‡∏ü\", \"‡∏£‡∏ñ\", \"‡∏£‡∏î\", \"‡∏ô‡πà‡∏≥\", \"‡∏ï‡πâ‡∏ô\", \"‡πÑ‡∏°‡πâ\", \"‡∏ï‡πâ‡∏ô‡πÑ‡∏°‡πâ\", \" \", \"‡∏ü‡πâ‡∏≤\"])\n",
        "\n",
        "def search_longest(term, dictionary):\n",
        "    term_length = len(term)\n",
        "    max_length = 0\n",
        "    for vocab in dictionary:\n",
        "        if term in vocab:\n",
        "            max_length = max(max_length, len(vocab))\n",
        "\n",
        "    return max_length == term_length\n",
        "\n",
        "def Dictionary_Tokenizer_LM_debug(sentence:str, dictionary: Set[str]):\n",
        "    buffer = \"\"\n",
        "    tokens = []\n",
        "    for char in sentence:\n",
        "        buffer += char\n",
        "        print(\"buffer\", buffer)\n",
        "        if search_longest(buffer, dictionary) == True:\n",
        "            print(\"select this token: {}\".format(buffer))\n",
        "            tokens.append(buffer)\n",
        "            buffer = \"\"\n",
        "            print(\"clear the buffer.\")\n",
        "            print(\"\")\n",
        "    return tokens\n",
        "\n",
        "def Dictionary_Tokenizer_LM(sentence:str, dictionary: Set[str]):\n",
        "    buffer = \"\"\n",
        "    tokens = []\n",
        "    for char in sentence:\n",
        "        buffer += char\n",
        "        if search_longest(buffer, dictionary) == True:\n",
        "            tokens.append(buffer)\n",
        "            buffer = \"\"\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiG8uoH-dCCq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "d307936d-62a9-4de0-f3f3-17fa4ccf656c"
      },
      "source": [
        "Dictionary_Tokenizer_LM_debug(\"‡∏â‡∏±‡∏ô‡∏ä‡∏≠‡∏ö ‡∏£‡∏ñ‡πÑ‡∏ü\", dictionary)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "buffer ‡∏â\n",
            "buffer ‡∏â‡∏±\n",
            "buffer ‡∏â‡∏±‡∏ô\n",
            "select this token: ‡∏â‡∏±‡∏ô\n",
            "clear the buffer.\n",
            "\n",
            "buffer ‡∏ä\n",
            "buffer ‡∏ä‡∏≠\n",
            "buffer ‡∏ä‡∏≠‡∏ö\n",
            "select this token: ‡∏ä‡∏≠‡∏ö\n",
            "clear the buffer.\n",
            "\n",
            "buffer  \n",
            "select this token:  \n",
            "clear the buffer.\n",
            "\n",
            "buffer ‡∏£\n",
            "buffer ‡∏£‡∏ñ\n",
            "buffer ‡∏£‡∏ñ‡πÑ\n",
            "buffer ‡∏£‡∏ñ‡πÑ‡∏ü\n",
            "select this token: ‡∏£‡∏ñ‡πÑ‡∏ü\n",
            "clear the buffer.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['‡∏â‡∏±‡∏ô', '‡∏ä‡∏≠‡∏ö', ' ', '‡∏£‡∏ñ‡πÑ‡∏ü']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmJ61VwhdCCt",
        "colab_type": "text"
      },
      "source": [
        "#### __Question 1:__ Create your own dictionary to tokenize the following sentences that can tokenize all the words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT-KUu8cdCCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sentences = [\n",
        "    \"‡∏Å‡∏£‡∏∞‡∏ó‡∏£‡∏ß‡∏á‡∏Ñ‡∏°‡∏ô‡∏≤‡∏Ñ‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏Å‡∏≤‡∏ï‡∏≤‡∏£‡πå ‡∏à‡∏±‡∏î‡∏á‡∏≤‡∏ô Qatar Information Technology Exhibition and Conference (QITCOM 2019)\",\n",
        "    \"‡∏ì ‡∏Å‡∏£‡∏∏‡∏á‡πÇ‡∏î‡∏Æ‡∏≤ ‡∏£‡∏±‡∏ê‡∏Å‡∏≤‡∏ï‡∏≤‡∏£‡πå\",\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8O-E5g9dCCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fill the vocabulary to dictionary_lm\n",
        "\n",
        "dictionary_lm = set([\n",
        "    \" \",\n",
        "    \"Qatar\",\n",
        "    \"Information\",\n",
        "    \"‡∏Å‡∏£‡∏∞‡∏ó‡∏£‡∏ß‡∏á‡∏Ñ‡∏°‡∏ô‡∏≤‡∏Ñ‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£\",\n",
        "    \"‡∏Å‡∏≤‡∏ï‡∏≤‡∏£‡πå\",\n",
        "    # add more vocab\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsgVKpWRdCCz",
        "colab_type": "text"
      },
      "source": [
        "__Test:__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdpDZalldCCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_Dictionary_Tokenizer_LM(dictionary_lm):\n",
        "    \n",
        "    tokens_list = [ Dictionary_Tokenizer_LM(sentence, dictionary_lm) for sentence in test_sentences]\n",
        "    character_count_expect = sum([len(sentence) for sentence in test_sentences])\n",
        "    character_count_actual = 0\n",
        "    for tokens in tokens_list:\n",
        "        character_count_actual += sum(map(lambda token : len(token),tokens))\n",
        "\n",
        "    if(character_count_actual == character_count_expect):\n",
        "        print(\"‚úÖ Test succeed. üòÅ\")\n",
        "        \n",
        "        print(\"\\n tokens_list: \", tokens_list)\n",
        "    else:\n",
        "        print(\"Test failed. üò≠\\n\")\n",
        "        \n",
        "        print(\"test_sentences\", test_sentences)\n",
        "        print(\"tokens_list\", tokens_list)\n",
        "        \n",
        "        print('')\n",
        "        print(\"character_count_actual != character_count_expect\")\n",
        "        print(\"{} != {}\".format(character_count_actual, character_count_expect))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4tRq3IpdCC2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "58065ac4-451c-492b-d30a-1f4533d2fc4a"
      },
      "source": [
        "# Run this block to test the code\n",
        "test_Dictionary_Tokenizer_LM(dictionary_lm)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test failed. üò≠\n",
            "\n",
            "test_sentences ['‡∏Å‡∏£‡∏∞‡∏ó‡∏£‡∏ß‡∏á‡∏Ñ‡∏°‡∏ô‡∏≤‡∏Ñ‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏Å‡∏≤‡∏ï‡∏≤‡∏£‡πå ‡∏à‡∏±‡∏î‡∏á‡∏≤‡∏ô Qatar Information Technology Exhibition and Conference (QITCOM 2019)', '‡∏ì ‡∏Å‡∏£‡∏∏‡∏á‡πÇ‡∏î‡∏Æ‡∏≤ ‡∏£‡∏±‡∏ê‡∏Å‡∏≤‡∏ï‡∏≤‡∏£‡πå']\n",
            "tokens_list [['‡∏Å‡∏£‡∏∞‡∏ó‡∏£‡∏ß‡∏á‡∏Ñ‡∏°‡∏ô‡∏≤‡∏Ñ‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£', '‡∏Å‡∏≤‡∏ï‡∏≤‡∏£‡πå', ' '], []]\n",
            "\n",
            "character_count_actual != character_count_expect\n",
            "33 != 128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5zHDQdMdCC4",
        "colab_type": "text"
      },
      "source": [
        "__Solution:__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHjOtKjCdCC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dictionary_lm = set([\n",
        "    \"Qatar\",\n",
        "    \"Information\",\n",
        "    \"‡∏Å‡∏£‡∏∞‡∏ó‡∏£‡∏ß‡∏á‡∏Ñ‡∏°‡∏ô‡∏≤‡∏Ñ‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£\",\n",
        "    \"‡∏Å‡∏≤‡∏ï‡∏≤‡∏£‡πå\",\n",
        "    \"‡∏ì\",\n",
        "    \"‡∏Å‡∏£‡∏∏‡∏á‡πÇ‡∏î‡∏Æ‡∏≤\",\n",
        "    \"‡∏£‡∏±‡∏ê\",\n",
        "    \" \",\n",
        "    \"‡∏à‡∏±‡∏î‡∏á‡∏≤‡∏ô\",\n",
        "    \"(\",\n",
        "    \")\",\n",
        "    \"QITCOM\", \"2019\",\n",
        "    \"Qatar\",\n",
        "    \"Information\",\n",
        "    \"Technology\",\n",
        "    \"Exhibition\",\n",
        "    \"and\",\n",
        "    \"Conference\"\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSo3E6jUdCC7",
        "colab_type": "code",
        "colab": {},
        "outputId": "ce39274a-533c-4903-9918-8c720db2ada8"
      },
      "source": [
        "test_Dictionary_Tokenizer_LM(dictionary_lm)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "‚úÖ Test succeed. üòÅ\n",
            "\n",
            " tokens_list:  [['‡∏Å‡∏£‡∏∞‡∏ó‡∏£‡∏ß‡∏á‡∏Ñ‡∏°‡∏ô‡∏≤‡∏Ñ‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£', '‡∏Å‡∏≤‡∏ï‡∏≤‡∏£‡πå', ' ', '‡∏à‡∏±‡∏î‡∏á‡∏≤‡∏ô', ' ', 'Qatar', ' ', 'Information', ' ', 'Technology', ' ', 'Exhibition', ' ', 'and', ' ', 'Conference', ' ', '(', 'QITCOM', ' ', '2019', ')'], ['‡∏ì', ' ', '‡∏Å‡∏£‡∏∏‡∏á‡πÇ‡∏î‡∏Æ‡∏≤', ' ', '‡∏£‡∏±‡∏ê', '‡∏Å‡∏≤‡∏ï‡∏≤‡∏£‡πå']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmgTnZOAdCC9",
        "colab_type": "text"
      },
      "source": [
        "#### 1.2 Maximal matching (MM)\n",
        "\n",
        "\n",
        "Unlike Longest Matching, Maximal matching is an algorithm to split words from a sentence in which it prefers minumum number of tokens to be splited.\n",
        "\n",
        "\n",
        "```python\n",
        "\n",
        "dictionary = set([\"‡∏£‡∏ñ\", \"‡∏£‡∏ñ‡πÑ‡∏ü\", \"‡∏ü‡πâ‡∏≤\", \"‡πÑ‡∏ü‡∏ü‡πâ‡∏≤\", \"‡πÉ‡∏ï‡πâ‡∏î‡∏¥‡∏ô\"])\n",
        "\n",
        "\n",
        "sentence = \"‡∏£‡∏ñ‡πÑ‡∏ü‡∏ü‡πâ‡∏≤‡πÉ‡∏ï‡πâ‡∏î‡∏¥‡∏ô\"\n",
        "\n",
        "Possible_segments(sentence) ->\n",
        "[\"‡∏£‡∏ñ‡πÑ‡∏ü\", \"‡∏ü‡πâ‡∏≤\", \"‡πÉ‡∏ï‡πâ‡∏î‡∏¥‡∏ô\"]\n",
        "[\"‡∏£‡∏ñ\", \"‡πÑ‡∏ü‡∏ü‡πâ‡∏≤\", \"‡πÉ‡∏ï‡πâ‡∏î‡∏¥‡∏ô\"]\n",
        "[\"‡∏£‡∏ñ‡πÑ‡∏ü‡∏ü‡πâ‡∏≤\", \"‡πÉ‡∏ï‡πâ‡∏î‡∏¥‡∏ô\"]\n",
        "\n",
        "\n",
        "selected_segment = [\"‡∏£‡∏ñ‡πÑ‡∏ü‡∏ü‡πâ‡∏≤\", \"‡πÉ‡∏ï‡πâ‡∏î‡∏¥‡∏ô\"]\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqZpRdwydCC-",
        "colab_type": "text"
      },
      "source": [
        "#### PyThaiNLP's Tokenizer (newmm)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M10q16kdCC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pythainlp.tokenize import word_tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjTgmlK7dCDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sentence = \"‡∏Å‡∏£‡∏∞‡∏ó‡∏£‡∏ß‡∏á‡∏Ñ‡∏°‡∏ô‡∏≤‡∏Ñ‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏Å‡∏≤‡∏ï‡∏≤‡∏£‡πå ‡∏à‡∏±‡∏î‡∏á‡∏≤‡∏ô Qatar Information Technology Exhibition and Conference (QITCOM 2019)\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOJQUzw9dCDD",
        "colab_type": "code",
        "colab": {},
        "outputId": "f8f9f9e4-4828-43b4-c91e-b04ce494dee8"
      },
      "source": [
        "tokens = word_tokenize(test_sentence, engine=\"newmm\")\n",
        "print(tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['‡∏Å‡∏£‡∏∞‡∏ó‡∏£‡∏ß‡∏á‡∏Ñ‡∏°‡∏ô‡∏≤‡∏Ñ‡∏°', '‡πÅ‡∏•‡∏∞', '‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£', '‡∏Å‡∏≤‡∏ï‡∏≤‡∏£‡πå', ' ', '‡∏à‡∏±‡∏î‡∏á‡∏≤‡∏ô', ' ', 'Qatar', ' ', 'Information', ' ', 'Technology', ' ', 'Exhibition', ' ', 'and', ' ', 'Conference', ' ', '(', 'QITCOM', ' ', '2019', ')']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djZBuOFWdCDG",
        "colab_type": "text"
      },
      "source": [
        "__Try out:__\n",
        "\n",
        "2.1 Try adding your own sentence.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVjwwTCsdCDH",
        "colab_type": "code",
        "colab": {},
        "outputId": "46e917e3-5b75-4fd5-c290-5856e5a74881"
      },
      "source": [
        "# Example sentence\n",
        "print(word_tokenize(\"‡∏â‡∏±‡∏ô‡∏≠‡∏¢‡∏∏‡πã‡∏ó‡∏µ‡πà ‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï‡∏û‡∏±‡∏í‡∏ô‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå\", engine=\"newmm\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['‡∏â‡∏±‡∏ô', '‡∏≠‡∏¢‡∏∏‡πã', '‡∏ó‡∏µ‡πà', ' ', '‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï‡∏û‡∏±‡∏í‡∏ô‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7Q0Oy07dCDJ",
        "colab_type": "code",
        "colab": {},
        "outputId": "7e8cb6ea-e722-4dcb-abe6-bb1a090263ea"
      },
      "source": [
        "# Enter you own setnence\n",
        "print(word_tokenize(\" \", engine=\"newmm\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f-PpDtCdCDL",
        "colab_type": "text"
      },
      "source": [
        "2.2 Try adding your own sentence with misspelling.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNSPhJ7gdCDM",
        "colab_type": "code",
        "colab": {},
        "outputId": "315c98f1-81e7-4e7a-aab6-a4d026de40f2"
      },
      "source": [
        "# Example sentence with misspelling words\n",
        "print(word_tokenize(\"‡∏â‡∏±‡∏ô‡∏≠‡∏¢‡∏∏‡πã‡∏ó‡∏µ‡πà ‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï‡∏û‡∏±‡∏í‡∏ô‡∏ö‡∏¢‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå\", engine=\"newmm\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['‡∏â‡∏±‡∏ô', '‡∏≠‡∏¢‡∏∏‡πã', '‡∏ó‡∏µ‡πà', ' ', '‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô', '‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï', '‡∏û‡∏±‡∏í‡∏ô', '‡∏ö‡∏¢', '‡∏£‡∏¥', '‡∏´‡∏≤‡∏£', '‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkjmqVUOdCDN",
        "colab_type": "code",
        "colab": {},
        "outputId": "c1d62cea-6faa-491f-a36d-13d00f993986"
      },
      "source": [
        "# Enter you own setnence\n",
        "print(word_tokenize(\" \", engine=\"newmm\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blpcwX4IdCDQ",
        "colab_type": "text"
      },
      "source": [
        "#### __Question 2:__ Add your own custom dictionary for `newmm` tokenizer to tokenize the into the following tokens:\n",
        "\n",
        "```\n",
        "\n",
        "\"‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 22 ‡∏ï.‡∏Ñ. ‡πÄ‡∏≠‡πÄ‡∏≠‡∏ü‡∏û‡∏µ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ß‡πà‡∏≤ ‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡∏û‡∏£‡∏∞‡∏à‡∏±‡∏Å‡∏£‡∏û‡∏£‡∏£‡∏î‡∏¥‡∏ô‡∏≤‡∏£‡∏∏‡∏Æ‡∏¥‡πÇ‡∏ï‡∏∞ ‡∏ó‡∏£‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏ä‡∏û‡∏¥‡∏ò‡∏µ‡∏ö‡∏£‡∏°‡∏£‡∏≤‡∏ä‡∏≤‡∏†‡∏¥‡πÄ‡∏©‡∏Å ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡∏û‡∏£‡∏∞‡∏à‡∏±‡∏Å‡∏£‡∏û‡∏£‡∏£‡∏î‡∏¥‡πÅ‡∏´‡πà‡∏á‡∏ç‡∏µ‡πà‡∏õ‡∏∏‡πà‡∏ô‡πÇ‡∏î‡∏¢‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏•‡πâ‡∏ß‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ ‡∏ó‡∏µ‡πà‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏ä‡∏ß‡∏±‡∏á‡∏´‡∏•‡∏ß‡∏á‡πÉ‡∏ô‡∏Å‡∏£‡∏∏‡∏á‡πÇ‡∏ï‡πÄ‡∏Å‡∏µ‡∏¢‡∏ß\",\n",
        "\n",
        "```\n",
        "\n",
        "Result with the default dictionary:\n",
        "\n",
        "```\n",
        "['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà', ' ', '22', ' ', '‡∏ï.‡∏Ñ.', ' ', '‡πÄ‡∏≠‡πÄ‡∏≠‡∏ü‡∏û‡∏µ', '‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô', '‡∏ß‡πà‡∏≤', ' ', '‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à', '‡∏û‡∏£‡∏∞', '‡∏à‡∏±‡∏Å‡∏£‡∏û‡∏£‡∏£‡∏î‡∏¥', '‡∏ô‡∏≤', '‡∏£‡∏∏', '‡∏Æ‡∏¥', '‡πÇ‡∏ï‡∏∞', ' ', '‡∏ó‡∏£‡∏á', '‡πÄ‡∏Ç‡πâ‡∏≤', '‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏ä‡∏û‡∏¥‡∏ò‡∏µ', '‡∏ö‡∏£‡∏°‡∏£‡∏≤‡∏ä‡∏≤‡∏†‡∏¥‡πÄ‡∏©‡∏Å', ' ', '‡πÄ‡∏õ‡πá‡∏ô', '‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à', '‡∏û‡∏£‡∏∞', '‡∏à‡∏±‡∏Å‡∏£‡∏û‡∏£‡∏£‡∏î‡∏¥', '‡πÅ‡∏´‡πà‡∏á', '‡∏ç‡∏µ‡πà‡∏õ‡∏∏‡πà‡∏ô', '‡πÇ‡∏î‡∏¢', '‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå', '‡πÅ‡∏•‡πâ‡∏ß', '‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ', ' ', '‡∏ó‡∏µ‡πà', '‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏ä‡∏ß‡∏±‡∏á', '‡∏´‡∏•‡∏ß‡∏á', '‡πÉ‡∏ô', '‡∏Å‡∏£‡∏∏‡∏á', '‡πÇ‡∏ï‡πÄ‡∏Å‡∏µ‡∏¢‡∏ß']\n",
        "```\n",
        "\n",
        "Expectation:\n",
        "```\n",
        "['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà', ' ', '22', ' ', '‡∏ï.‡∏Ñ.', ' ', '‡πÄ‡∏≠‡πÄ‡∏≠‡∏ü‡∏û‡∏µ', '‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô', '‡∏ß‡πà‡∏≤', ' ', '‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡∏û‡∏£‡∏∞‡∏à‡∏±‡∏Å‡∏£‡∏û‡∏£‡∏£‡∏î‡∏¥', '‡∏ô‡∏≤‡∏£‡∏∏‡∏Æ‡∏¥‡πÇ‡∏ï‡∏∞', ' ', '‡∏ó‡∏£‡∏á', '‡πÄ‡∏Ç‡πâ‡∏≤', '‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏ä‡∏û‡∏¥‡∏ò‡∏µ', '‡∏ö‡∏£‡∏°‡∏£‡∏≤‡∏ä‡∏≤‡∏†‡∏¥‡πÄ‡∏©‡∏Å', ' ', '‡πÄ‡∏õ‡πá‡∏ô', '‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡∏û‡∏£‡∏∞‡∏à‡∏±‡∏Å‡∏£‡∏û‡∏£‡∏£‡∏î‡∏¥', '‡πÅ‡∏´‡πà‡∏á', '‡∏ç‡∏µ‡πà‡∏õ‡∏∏‡πà‡∏ô', '‡πÇ‡∏î‡∏¢', '‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå', '‡πÅ‡∏•‡πâ‡∏ß', '‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ', ' ', '‡∏ó‡∏µ‡πà', '‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏ä‡∏ß‡∏±‡∏á', '‡∏´‡∏•‡∏ß‡∏á', '‡πÉ‡∏ô', '‡∏Å‡∏£‡∏∏‡∏á‡πÇ‡∏ï‡πÄ‡∏Å‡∏µ‡∏¢‡∏ß']\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VASYtZq9dCDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pythainlp.tokenize.trie import Trie\n",
        "from pythainlp.corpus import thai_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oye-sEuXdCDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_from_news = \"\"\"‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 22 ‡∏ï.‡∏Ñ. ‡πÄ‡∏≠‡πÄ‡∏≠‡∏ü‡∏û‡∏µ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ß‡πà‡∏≤ ‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡∏û‡∏£‡∏∞‡∏à‡∏±‡∏Å‡∏£‡∏û‡∏£‡∏£‡∏î‡∏¥‡∏ô‡∏≤‡∏£‡∏∏‡∏Æ‡∏¥‡πÇ‡∏ï‡∏∞ ‡∏ó‡∏£‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏ä‡∏û‡∏¥‡∏ò‡∏µ‡∏ö‡∏£‡∏°‡∏£‡∏≤‡∏ä‡∏≤‡∏†‡∏¥‡πÄ‡∏©‡∏Å ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡∏û‡∏£‡∏∞‡∏à‡∏±‡∏Å‡∏£‡∏û‡∏£‡∏£‡∏î‡∏¥‡πÅ‡∏´‡πà‡∏á‡∏ç‡∏µ‡πà‡∏õ‡∏∏‡πà‡∏ô‡πÇ‡∏î‡∏¢‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏•‡πâ‡∏ß‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ ‡∏ó‡∏µ‡πà‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏ä‡∏ß‡∏±‡∏á‡∏´‡∏•‡∏ß‡∏á‡πÉ‡∏ô‡∏Å‡∏£‡∏∏‡∏á‡πÇ‡∏ï‡πÄ‡∏Å‡∏µ‡∏¢‡∏ß\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feTxEFsxdCDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add vocab in this list\n",
        "custom_vocab = [\n",
        "    \n",
        "    \n",
        "]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWFsGmh2dCDW",
        "colab_type": "text"
      },
      "source": [
        "__Test:__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M12ugrhEdCDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_tokenize_japan_news(custom_vocab):\n",
        "    expect = ['‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà', ' ', '22', ' ', '‡∏ï.‡∏Ñ.', ' ', '‡πÄ‡∏≠‡πÄ‡∏≠‡∏ü‡∏û‡∏µ', '‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô', '‡∏ß‡πà‡∏≤', ' ',\n",
        "              '‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡∏û‡∏£‡∏∞‡∏à‡∏±‡∏Å‡∏£‡∏û‡∏£‡∏£‡∏î‡∏¥', '‡∏ô‡∏≤‡∏£‡∏∏‡∏Æ‡∏¥‡πÇ‡∏ï‡∏∞', ' ', '‡∏ó‡∏£‡∏á', '‡πÄ‡∏Ç‡πâ‡∏≤', '‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏ä‡∏û‡∏¥‡∏ò‡∏µ', '‡∏ö‡∏£‡∏°‡∏£‡∏≤‡∏ä‡∏≤‡∏†‡∏¥‡πÄ‡∏©‡∏Å',\n",
        "              ' ', '‡πÄ‡∏õ‡πá‡∏ô', '‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡∏û‡∏£‡∏∞‡∏à‡∏±‡∏Å‡∏£‡∏û‡∏£‡∏£‡∏î‡∏¥', '‡πÅ‡∏´‡πà‡∏á', '‡∏ç‡∏µ‡πà‡∏õ‡∏∏‡πà‡∏ô', '‡πÇ‡∏î‡∏¢', '‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå', '‡πÅ‡∏•‡πâ‡∏ß', '‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ',\n",
        "              ' ', '‡∏ó‡∏µ‡πà', '‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏ä‡∏ß‡∏±‡∏á', '‡∏´‡∏•‡∏ß‡∏á', '‡πÉ‡∏ô', '‡∏Å‡∏£‡∏∏‡∏á‡πÇ‡∏ï‡πÄ‡∏Å‡∏µ‡∏¢‡∏ß']\n",
        "    \n",
        "    custom_dict_trie = Trie( list(thai_words()) + custom_vocab)\n",
        "\n",
        "    actual = word_tokenize(text_from_news, custom_dict=custom_dict_trie, engine=\"newmm\")\n",
        "    \n",
        "    \n",
        "   \n",
        "    if actual == expect:\n",
        "        print(\"‚úÖ Test succeed. üòÅ\")\n",
        "    else:\n",
        "        print(\"‚ùå Test failed. üò≠\")\n",
        "        print(\"\\nYour result    :\\n\\n\", \"|\".join(actual))\n",
        "        print(\"\\nExtected result:\\n\\n\", \"|\".join(expect))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg7jdiA9dCDY",
        "colab_type": "code",
        "colab": {},
        "outputId": "2696b7cb-c89e-4fcc-d708-20fc5a9a1847"
      },
      "source": [
        "test_tokenize_japan_news(custom_vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "‚ùå Test failed. üò≠\n",
            "\n",
            "Your result    :\n",
            "\n",
            " ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà| |22| |‡∏ï.‡∏Ñ.| |‡πÄ‡∏≠‡πÄ‡∏≠‡∏ü‡∏û‡∏µ|‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô|‡∏ß‡πà‡∏≤| |‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à|‡∏û‡∏£‡∏∞|‡∏à‡∏±‡∏Å‡∏£‡∏û‡∏£‡∏£‡∏î‡∏¥|‡∏ô‡∏≤|‡∏£‡∏∏|‡∏Æ‡∏¥|‡πÇ‡∏ï‡∏∞| |‡∏ó‡∏£‡∏á|‡πÄ‡∏Ç‡πâ‡∏≤|‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏ä‡∏û‡∏¥‡∏ò‡∏µ|‡∏ö‡∏£‡∏°‡∏£‡∏≤‡∏ä‡∏≤‡∏†‡∏¥‡πÄ‡∏©‡∏Å| |‡πÄ‡∏õ‡πá‡∏ô|‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à|‡∏û‡∏£‡∏∞|‡∏à‡∏±‡∏Å‡∏£‡∏û‡∏£‡∏£‡∏î‡∏¥|‡πÅ‡∏´‡πà‡∏á|‡∏ç‡∏µ‡πà‡∏õ‡∏∏‡πà‡∏ô|‡πÇ‡∏î‡∏¢|‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå|‡πÅ‡∏•‡πâ‡∏ß|‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ| |‡∏ó‡∏µ‡πà|‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏ä‡∏ß‡∏±‡∏á|‡∏´‡∏•‡∏ß‡∏á|‡πÉ‡∏ô|‡∏Å‡∏£‡∏∏‡∏á|‡πÇ‡∏ï‡πÄ‡∏Å‡∏µ‡∏¢‡∏ß\n",
            "\n",
            "Extected result:\n",
            "\n",
            " ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà| |22| |‡∏ï.‡∏Ñ.| |‡πÄ‡∏≠‡πÄ‡∏≠‡∏ü‡∏û‡∏µ|‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô|‡∏ß‡πà‡∏≤| |‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡∏û‡∏£‡∏∞‡∏à‡∏±‡∏Å‡∏£‡∏û‡∏£‡∏£‡∏î‡∏¥|‡∏ô‡∏≤‡∏£‡∏∏‡∏Æ‡∏¥‡πÇ‡∏ï‡∏∞| |‡∏ó‡∏£‡∏á|‡πÄ‡∏Ç‡πâ‡∏≤|‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏ä‡∏û‡∏¥‡∏ò‡∏µ|‡∏ö‡∏£‡∏°‡∏£‡∏≤‡∏ä‡∏≤‡∏†‡∏¥‡πÄ‡∏©‡∏Å| |‡πÄ‡∏õ‡πá‡∏ô|‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡∏û‡∏£‡∏∞‡∏à‡∏±‡∏Å‡∏£‡∏û‡∏£‡∏£‡∏î‡∏¥|‡πÅ‡∏´‡πà‡∏á|‡∏ç‡∏µ‡πà‡∏õ‡∏∏‡πà‡∏ô|‡πÇ‡∏î‡∏¢|‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå|‡πÅ‡∏•‡πâ‡∏ß|‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ| |‡∏ó‡∏µ‡πà|‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏ä‡∏ß‡∏±‡∏á|‡∏´‡∏•‡∏ß‡∏á|‡πÉ‡∏ô|‡∏Å‡∏£‡∏∏‡∏á‡πÇ‡∏ï‡πÄ‡∏Å‡∏µ‡∏¢‡∏ß\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XYVeK3TdCDa",
        "colab_type": "text"
      },
      "source": [
        "__Solution:__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgqw4IKkdCDb",
        "colab_type": "code",
        "colab": {},
        "outputId": "1614ce41-ba69-42fc-e3cc-f76d3440f032"
      },
      "source": [
        "# Add vocab\n",
        "custom_vocab = [\n",
        "    \"‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡∏û‡∏£‡∏∞‡∏à‡∏±‡∏Å‡∏£‡∏û‡∏£‡∏£‡∏î‡∏¥\",\n",
        "    \"‡∏Å‡∏£‡∏∏‡∏á‡πÇ‡∏ï‡πÄ‡∏Å‡∏µ‡∏¢‡∏ß\",\n",
        "    \"‡∏ô‡∏≤‡∏£‡∏∏‡∏Æ‡∏¥‡πÇ‡∏ï‡∏∞\"\n",
        "]\n",
        "\n",
        "test_tokenize_japan_news(custom_vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "‚úÖ Test succeed. üòÅ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": false,
        "id": "alP5sF__dCDe",
        "colab_type": "text"
      },
      "source": [
        "### Learning-based tokenizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqYSqnlgdCDf",
        "colab_type": "text"
      },
      "source": [
        "Tokenizer is a Machine Learning model and train on supervised daataset (labeled dataset).\n",
        "\n",
        "\n",
        "For example, one tokenizer of PyThaiNLP (`attacut`) uses Convolutional-neural Network to read the whole text and then determind word boundaries.\n",
        "\n",
        "![attacut](https://github.com/korakot/pythainlp_workshop/blob/master/notebooks/images/attacut.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGy5lXUydCDf",
        "colab_type": "text"
      },
      "source": [
        "#### attacut"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ficBJ7DTdCDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q attacut"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhVeWIMZdCDi",
        "colab_type": "code",
        "colab": {},
        "outputId": "c91da7db-538e-4d1e-df8e-488ce6f37240"
      },
      "source": [
        "test_sentence = \"‡∏Å‡∏£‡∏∞‡∏ó‡∏£‡∏ß‡∏á‡∏Ñ‡∏°‡∏ô‡∏≤‡∏Ñ‡∏°‡πÅ‡∏•‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏Å‡∏≤‡∏ï‡∏≤‡∏£‡πå ‡∏à‡∏±‡∏î‡∏á‡∏≤‡∏ô Qatar Information Technology Exhibition and Conference (QITCOM 2019)\"\n",
        "\n",
        "tokens = word_tokenize(test_sentence, engine=\"attacut\")\n",
        "print(tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['‡∏Å‡∏£‡∏∞‡∏ó‡∏£‡∏ß‡∏á‡∏Ñ‡∏°‡∏ô‡∏≤‡∏Ñ‡∏°', '‡πÅ‡∏•‡∏∞', '‡∏Å‡∏≤‡∏£‡∏™‡∏∑‡πà‡∏≠‡∏™‡∏≤‡∏£‡∏Å‡∏≤‡∏ï‡∏≤‡∏£‡πå', ' ', '‡∏à‡∏±‡∏î', '‡∏á‡∏≤‡∏ô', ' ', 'Qatar', ' ', 'Information', ' ', 'Technology', ' ', 'Exhibition', ' ', 'and', ' ', 'Conference', ' ', '(', 'QITCOM', ' ', '2019', ')']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fcn3UDaLdCDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAddG_UsdCDm",
        "colab_type": "code",
        "colab": {},
        "outputId": "7ee42e89-86a3-40da-cefb-ff6f9c7772c8"
      },
      "source": [
        "test_sentence = \"‡∏â‡∏±‡∏ô‡∏≠‡∏¢‡∏∏‡πã‡∏ó‡∏µ‡πà ‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï‡∏û‡∏±‡∏í‡∏ô‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå\"\n",
        "\n",
        "tokens = word_tokenize(test_sentence, engine=\"attacut\")\n",
        "print(tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['‡∏â‡∏±‡∏ô', '‡∏≠‡∏¢‡∏∏‡πã', '‡∏ó‡∏µ‡πà', ' ', '‡∏™‡∏ñ‡∏≤‡∏ö‡∏±‡∏ô‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï‡∏û‡∏±‡∏í‡∏ô‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Fkps71WdCDo",
        "colab_type": "text"
      },
      "source": [
        "__Try out:__ Try adding your own sentence.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXa100KNdCDp",
        "colab_type": "code",
        "colab": {},
        "outputId": "48623a80-92ba-47c6-c77a-a5621bf20e27"
      },
      "source": [
        "# Enter you own setnence\n",
        "print(word_tokenize(\" \", engine=\"attacut\"))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": false,
        "id": "wYtc1sbvdCDq",
        "colab_type": "text"
      },
      "source": [
        "## 2. Part of speech and Named Entity Recognition Tagging\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1-MSoWgdCDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q sklearn_crfsuite"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8eRAxyrdCDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pythainlp.tag.named_entity import ThaiNameTagger\n",
        "\n",
        "tagger = ThaiNameTagger()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-Nv83L3dCDw",
        "colab_type": "text"
      },
      "source": [
        "#### Named Entitiy Regcognition (NER) Tags:\n",
        "\n",
        "|       Tags       |      Examples                       |\n",
        "|------------------|-------------------------------------|\n",
        "        DATE       |   1 ‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏° 2012                      |\n",
        "        EMAIL      |   hr@mycompany.com                  |    \n",
        "        LAW        |  ‡∏û‡∏£‡∏ö.‡∏Ñ‡∏∏‡πâ‡∏°‡∏Ñ‡∏£‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡πÇ‡∏†‡∏Ñ                   |\n",
        "        LEN        |       80 ‡∏Å‡∏¥‡πÇ‡∏•‡πÄ‡∏°‡∏ï‡∏£                    |     \n",
        "      LOCATION     |  ‡∏Å‡∏£‡∏∏‡∏á‡πÄ‡∏ó‡∏û, ‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏à‡∏µ‡∏ô, ‡πÄ‡∏≠‡πÄ‡∏ß‡∏≠‡πÄ‡∏£‡∏™‡∏ï‡πå        | \n",
        "        MONEY      |   2,190 ‡∏•‡πâ‡∏≤‡∏ô‡∏ö‡∏≤‡∏ó                      |\n",
        "    ORGANIZATION   |  ‡∏Ñ‡∏ì‡∏∞‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå ‡∏à‡∏∏‡∏¨‡∏≤‡∏•‡∏á‡∏Å‡∏£‡∏ì‡πå‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢     |\n",
        "       PERCENT     |   95.34%, 10‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÄ‡∏ã‡∏ô‡∏ï‡πå                |\n",
        "       PERSON      |   ‡∏≠‡∏£‡∏£‡∏ñ‡∏û‡∏• ‡∏ò‡∏≥‡∏£‡∏á‡∏£‡∏±‡∏ï‡∏ô‡∏§‡∏ó‡∏ò‡∏¥‡πå                 |\n",
        "        PHONE      |   +6611-123-1123                    |\n",
        "         TIME      |      14:20 ‡∏ô, ‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏ó‡∏µ‡πà‡∏¢‡∏á‡∏ï‡∏£‡∏á           |\n",
        "          URL      |     mycompany.com                   |\n",
        "         ZIP       |     ‡∏£‡∏´‡∏±‡∏™‡πÑ‡∏õ‡∏£‡∏ì‡∏µ‡∏¢‡πå 21210                  |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lin9_degdCDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = \"‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ ‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 1 ‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏° ‡πÑ‡∏î‡πâ‡πÑ‡∏õ‡∏á‡∏≤‡∏ô‡πÄ‡∏õ‡∏¥‡∏î‡∏ö‡πâ‡∏≤‡∏ô ‡∏ó‡∏µ‡πà‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢‡∏ò‡∏£‡∏£‡∏°‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMBecyjJdCDz",
        "colab_type": "code",
        "colab": {},
        "outputId": "c47c93e1-3725-4ebc-ebc0-3aeeed27d8dc"
      },
      "source": [
        "tagger.get_ner(sentence, pos=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ', 'B-DATE'),\n",
              " (' ', 'O'),\n",
              " ('‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà', 'O'),\n",
              " (' ', 'O'),\n",
              " ('1', 'B-DATE'),\n",
              " (' ', 'I-DATE'),\n",
              " ('‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°', 'I-DATE'),\n",
              " (' ', 'O'),\n",
              " ('‡πÑ‡∏î‡πâ', 'O'),\n",
              " ('‡πÑ‡∏õ', 'O'),\n",
              " ('‡∏á‡∏≤‡∏ô', 'O'),\n",
              " ('‡πÄ‡∏õ‡∏¥‡∏î', 'O'),\n",
              " ('‡∏ö‡πâ‡∏≤‡∏ô', 'O'),\n",
              " (' ', 'O'),\n",
              " ('‡∏ó‡∏µ‡πà', 'O'),\n",
              " ('‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢‡∏ò‡∏£‡∏£‡∏°‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå', 'B-LOCATION')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62htot2RdCD0",
        "colab_type": "code",
        "colab": {},
        "outputId": "e637dec2-0181-4557-b18d-dfe47ab53f51"
      },
      "source": [
        "tagger.get_ner(sentence, pos=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ', 'NOUN', 'B-DATE'),\n",
              " (' ', 'PUNCT', 'O'),\n",
              " ('‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà', 'NOUN', 'O'),\n",
              " (' ', 'PUNCT', 'O'),\n",
              " ('1', 'NUM', 'B-DATE'),\n",
              " (' ', 'PUNCT', 'I-DATE'),\n",
              " ('‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°', 'NOUN', 'I-DATE'),\n",
              " (' ', 'PUNCT', 'O'),\n",
              " ('‡πÑ‡∏î‡πâ', 'AUX', 'O'),\n",
              " ('‡πÑ‡∏õ', 'VERB', 'O'),\n",
              " ('‡∏á‡∏≤‡∏ô', 'NOUN', 'O'),\n",
              " ('‡πÄ‡∏õ‡∏¥‡∏î', 'VERB', 'O'),\n",
              " ('‡∏ö‡πâ‡∏≤‡∏ô', 'NOUN', 'O'),\n",
              " (' ', 'PUNCT', 'O'),\n",
              " ('‡∏ó‡∏µ‡πà', 'SCONJ', 'O'),\n",
              " ('‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢‡∏ò‡∏£‡∏£‡∏°‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå', 'NOUN', 'B-LOCATION')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agCxSj_odCD2",
        "colab_type": "text"
      },
      "source": [
        "#### __Question 3:__ From the following setentences how many types of named-entity appear in the sentence\n",
        "\n",
        "\n",
        "```text\n",
        "‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà ‡πì‡πë ‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏° ‡πí‡πï‡πñ‡πí ‡πÄ‡∏ß‡∏•‡∏≤ 13:00 ‡∏ô. ‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt1u-YjydCD2",
        "colab_type": "code",
        "colab": {},
        "outputId": "04e50696-5a10-4fd4-d664-ba3cc7c8badd"
      },
      "source": [
        "tagger.get_ner(\"‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà ‡πì‡πë ‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏° ‡πí‡πï‡πñ‡πí ‡πÄ‡∏ß‡∏•‡∏≤ 13:00 ‡∏ô. ‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢\", pos=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('‡πÄ‡∏°‡∏∑‡πà‡∏≠', 'O'),\n",
              " ('‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà', 'O'),\n",
              " (' ', 'O'),\n",
              " ('‡πì‡πë', 'B-DATE'),\n",
              " (' ', 'I-DATE'),\n",
              " ('‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°', 'I-DATE'),\n",
              " (' ', 'I-DATE'),\n",
              " ('‡πí‡πï‡πñ‡πí', 'I-DATE'),\n",
              " (' ', 'O'),\n",
              " ('‡πÄ‡∏ß‡∏•‡∏≤', 'O'),\n",
              " (' ', 'O'),\n",
              " ('13', 'B-TIME'),\n",
              " (':', 'I-TIME'),\n",
              " ('00', 'I-TIME'),\n",
              " (' ', 'I-TIME'),\n",
              " ('‡∏ô.', 'I-TIME'),\n",
              " (' ', 'O'),\n",
              " ('‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤', 'O'),\n",
              " ('‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®', 'O'),\n",
              " ('‡πÑ‡∏ó‡∏¢', 'B-LOCATION')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGGfbqF4dCD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrqforwGdCD7",
        "colab_type": "text"
      },
      "source": [
        "#### __Question 4:__ From the following setentences how many types of named-entity appear in the sentence\n",
        "\n",
        "Reference: https://www.khaosod.co.th/around-the-world-news/news_2993136\n",
        "\n",
        "```text\n",
        "‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 22 ‡∏ï.‡∏Ñ. ‡πÄ‡∏≠‡πÄ‡∏≠‡∏ü‡∏û‡∏µ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ß‡πà‡∏≤ ‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡∏û‡∏£‡∏∞‡∏à‡∏±‡∏Å‡∏£‡∏û‡∏£‡∏£‡∏î‡∏¥‡∏ô‡∏≤‡∏£‡∏∏‡∏Æ‡∏¥‡πÇ‡∏ï‡∏∞ ‡∏ó‡∏£‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏ä‡∏û‡∏¥‡∏ò‡∏µ‡∏ö‡∏£‡∏°‡∏£‡∏≤‡∏ä‡∏≤‡∏†‡∏¥‡πÄ‡∏©‡∏Å\n",
        "‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡∏û‡∏£‡∏∞‡∏à‡∏±‡∏Å‡∏£‡∏û‡∏£‡∏£‡∏î‡∏¥‡πÅ‡∏´‡πà‡∏á‡∏ç‡∏µ‡πà‡∏õ‡∏∏‡πà‡∏ô‡πÇ‡∏î‡∏¢‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏•‡πâ‡∏ß‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ ‡∏ó‡∏µ‡πà‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏ä‡∏ß‡∏±‡∏á‡∏´‡∏•‡∏ß‡∏á‡πÉ‡∏ô‡∏Å‡∏£‡∏∏‡∏á‡πÇ‡∏ï‡πÄ‡∏Å‡∏µ‡∏¢‡∏ß\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0y2fZmNdCD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqRf8S-pdCD-",
        "colab_type": "code",
        "colab": {},
        "outputId": "a0283882-1b9d-42d0-ccc9-51c11b1599f5"
      },
      "source": [
        "# Try out\n",
        "tagger.get_ner(\"‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 22 ‡∏ï.‡∏Ñ. ‡πÄ‡∏≠‡πÄ‡∏≠‡∏ü‡∏û‡∏µ‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏ß‡πà‡∏≤ ‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡∏û‡∏£‡∏∞‡∏à‡∏±‡∏Å‡∏£‡∏û‡∏£‡∏£‡∏î‡∏¥‡∏ô‡∏≤‡∏£‡∏∏‡∏Æ‡∏¥‡πÇ‡∏ï‡∏∞ ‡∏ó‡∏£‡∏á‡πÄ‡∏Ç‡πâ‡∏≤‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏ä‡∏û‡∏¥‡∏ò‡∏µ‡∏ö‡∏£‡∏°‡∏£‡∏≤‡∏ä‡∏≤‡∏†‡∏¥‡πÄ‡∏©‡∏Å ‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à‡∏û‡∏£‡∏∞‡∏à‡∏±‡∏Å‡∏£‡∏û‡∏£‡∏£‡∏î‡∏¥‡πÅ‡∏´‡πà‡∏á‡∏ç‡∏µ‡πà‡∏õ‡∏∏‡πà‡∏ô‡πÇ‡∏î‡∏¢‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå‡πÅ‡∏•‡πâ‡∏ß‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ ‡∏ó‡∏µ‡πà‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏ä‡∏ß‡∏±‡∏á‡∏´‡∏•‡∏ß‡∏á‡πÉ‡∏ô‡∏Å‡∏£‡∏∏‡∏á‡πÇ‡∏ï‡πÄ‡∏Å‡∏µ‡∏¢‡∏ß\", pos=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà', 'O'),\n",
              " (' ', 'O'),\n",
              " ('22', 'B-DATE'),\n",
              " (' ', 'I-DATE'),\n",
              " ('‡∏ï.‡∏Ñ.', 'I-DATE'),\n",
              " (' ', 'O'),\n",
              " ('‡πÄ‡∏≠‡πÄ‡∏≠‡∏ü‡∏û‡∏µ', 'B-ORGANIZATION'),\n",
              " ('‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô', 'O'),\n",
              " ('‡∏ß‡πà‡∏≤', 'O'),\n",
              " (' ', 'O'),\n",
              " ('‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à', 'B-PERSON'),\n",
              " ('‡∏û‡∏£‡∏∞', 'I-PERSON'),\n",
              " ('‡∏à‡∏±‡∏Å‡∏£‡∏û‡∏£‡∏£‡∏î‡∏¥', 'I-PERSON'),\n",
              " ('‡∏ô‡∏≤', 'I-PERSON'),\n",
              " ('‡∏£‡∏∏', 'I-PERSON'),\n",
              " ('‡∏Æ‡∏¥', 'I-PERSON'),\n",
              " ('‡πÇ‡∏ï‡∏∞', 'I-PERSON'),\n",
              " (' ', 'O'),\n",
              " ('‡∏ó‡∏£‡∏á', 'O'),\n",
              " ('‡πÄ‡∏Ç‡πâ‡∏≤', 'O'),\n",
              " ('‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏ä‡∏û‡∏¥‡∏ò‡∏µ', 'O'),\n",
              " ('‡∏ö‡∏£‡∏°‡∏£‡∏≤‡∏ä‡∏≤‡∏†‡∏¥‡πÄ‡∏©‡∏Å', 'O'),\n",
              " (' ', 'O'),\n",
              " ('‡πÄ‡∏õ‡πá‡∏ô', 'O'),\n",
              " ('‡∏™‡∏°‡πÄ‡∏î‡πá‡∏à', 'O'),\n",
              " ('‡∏û‡∏£‡∏∞', 'O'),\n",
              " ('‡∏à‡∏±‡∏Å‡∏£‡∏û‡∏£‡∏£‡∏î‡∏¥', 'O'),\n",
              " ('‡πÅ‡∏´‡πà‡∏á', 'O'),\n",
              " ('‡∏ç‡∏µ‡πà‡∏õ‡∏∏‡πà‡∏ô', 'B-LOCATION'),\n",
              " ('‡πÇ‡∏î‡∏¢', 'O'),\n",
              " ('‡∏™‡∏°‡∏ö‡∏π‡∏£‡∏ì‡πå', 'O'),\n",
              " ('‡πÅ‡∏•‡πâ‡∏ß', 'O'),\n",
              " ('‡∏ß‡∏±‡∏ô‡∏ô‡∏µ‡πâ', 'B-DATE'),\n",
              " (' ', 'O'),\n",
              " ('‡∏ó‡∏µ‡πà', 'O'),\n",
              " ('‡∏û‡∏£‡∏∞‡∏£‡∏≤‡∏ä‡∏ß‡∏±‡∏á', 'B-LOCATION'),\n",
              " ('‡∏´‡∏•‡∏ß‡∏á', 'I-LOCATION'),\n",
              " ('‡πÉ‡∏ô', 'O'),\n",
              " ('‡∏Å‡∏£‡∏∏‡∏á', 'B-LOCATION'),\n",
              " ('‡πÇ‡∏ï‡πÄ‡∏Å‡∏µ‡∏¢‡∏ß', 'I-LOCATION')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGlkEIMedCD_",
        "colab_type": "text"
      },
      "source": [
        "#### __Question 5:__ From the following setentences how many types of named-entity appear in the sentence\n",
        "\n",
        "Reference: [link](http://www.arts.chula.ac.th/ling/blog/tag/%E0%B8%AD%E0%B8%A3%E0%B8%A3%E0%B8%96%E0%B8%9E%E0%B8%A5-%E0%B8%98%E0%B8%B3%E0%B8%A3%E0%B8%87%E0%B8%A3%E0%B8%B1%E0%B8%95%E0%B8%99%E0%B8%A4%E0%B8%97%E0%B8%98%E0%B8%B4%E0%B9%8C/)\n",
        "\n",
        "```text\n",
        "‡∏Ñ‡∏ì‡∏∞‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå ‡∏à‡∏∏‡∏¨‡∏≤‡∏•‡∏á‡∏Å‡∏£‡∏ì‡πå‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢ ‡∏Ç‡∏≠‡πÄ‡∏ä‡∏¥‡∏ç‡∏ä‡∏ß‡∏ô‡∏ú‡∏π‡πâ‡∏™‡∏ô‡πÉ‡∏à‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡πà‡∏ß‡∏°‡∏ü‡∏±‡∏á‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏¢‡∏û‡∏¥‡πÄ‡∏®‡∏©\n",
        "‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á ‚Äú‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏õ‡∏£‡∏¥‡∏à‡πÄ‡∏â‡∏ó‡πÅ‡∏ö‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏Ñ‡∏≥‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‚Äù\n",
        "‡πÇ‡∏î‡∏¢ ‡∏î‡∏£.‡∏≠‡∏£‡∏£‡∏ñ‡∏û‡∏• ‡∏ò‡∏≥‡∏£‡∏á‡∏£‡∏±‡∏ï‡∏ô‡∏§‡∏ó‡∏ò‡∏¥‡πå\n",
        "\n",
        "‡∏ß‡∏±‡∏ô‡∏®‡∏∏‡∏Å‡∏£‡πå‡∏ó‡∏µ‡πà 17 ‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô 2560 ‡πÄ‡∏ß‡∏•‡∏≤ 13.30-14.30 ‡∏ô.\n",
        "‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏ô‡πÑ‡∏õ ‡∏ì ‡∏´‡πâ‡∏≠‡∏á 401/5 ‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£‡∏°‡∏´‡∏≤‡∏à‡∏±‡∏Å‡∏£‡∏µ‡∏™‡∏¥‡∏£‡∏¥‡∏ô‡∏ò‡∏£ ‡∏Ñ‡∏ì‡∏∞‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå ‡∏à‡∏∏‡∏¨‡∏≤‡∏•‡∏á‡∏Å‡∏£‡∏ì‡πå‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢\n",
        "\n",
        "‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà 0-2218-4692\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYo5gOgGdCEA",
        "colab_type": "code",
        "colab": {},
        "outputId": "b6879c0c-2b36-4bef-e50c-f376220d0396"
      },
      "source": [
        "text = \"\"\"‡∏Ñ‡∏ì‡∏∞‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå ‡∏à‡∏∏‡∏¨‡∏≤‡∏•‡∏á‡∏Å‡∏£‡∏ì‡πå‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢\n",
        "‡∏Ç‡∏≠‡πÄ‡∏ä‡∏¥‡∏ç‡∏ä‡∏ß‡∏ô‡∏ú‡∏π‡πâ‡∏™‡∏ô‡πÉ‡∏à‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡πà‡∏ß‡∏°‡∏ü‡∏±‡∏á‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏¢‡∏û‡∏¥‡πÄ‡∏®‡∏© \n",
        "‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á ‚Äú‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏õ‡∏£‡∏¥‡∏à‡πÄ‡∏â‡∏ó‡πÅ‡∏ö‡∏ö‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥‡∏î‡πâ‡∏ß‡∏¢‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏Ñ‡∏≥‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°‚Äù\n",
        "‡πÇ‡∏î‡∏¢ ‡∏î‡∏£.‡∏≠‡∏£‡∏£‡∏ñ‡∏û‡∏• ‡∏ò‡∏≥‡∏£‡∏á‡∏£‡∏±‡∏ï‡∏ô‡∏§‡∏ó‡∏ò‡∏¥‡πå\n",
        "‡∏ß‡∏±‡∏ô‡∏®‡∏∏‡∏Å‡∏£‡πå‡∏ó‡∏µ‡πà 17 ‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô 2560 ‡πÄ‡∏ß‡∏•‡∏≤ 13.30-14.30 ‡∏ô. ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏ô‡πÑ‡∏õ ‡∏ì ‡∏´‡πâ‡∏≠‡∏á 401/5 ‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£‡∏°‡∏´‡∏≤‡∏à‡∏±‡∏Å‡∏£‡∏µ‡∏™‡∏¥‡∏£‡∏¥‡∏ô‡∏ò‡∏£ ‡∏Ñ‡∏ì‡∏∞‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå ‡∏à‡∏∏‡∏¨‡∏≤‡∏•‡∏á‡∏Å‡∏£‡∏ì‡πå‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢\n",
        "‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà 0-2218-4692\n",
        "\"\"\"\n",
        "\n",
        "tagger.get_ner(text, pos=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('‡∏Ñ‡∏ì‡∏∞‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå', 'B-ORGANIZATION'),\n",
              " (' ', 'O'),\n",
              " ('‡∏à‡∏∏‡∏¨‡∏≤‡∏•‡∏á‡∏Å‡∏£‡∏ì‡πå', 'B-ORGANIZATION'),\n",
              " ('‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢', 'I-ORGANIZATION'),\n",
              " ('\\n', 'O'),\n",
              " ('‡∏Ç‡∏≠', 'O'),\n",
              " ('‡πÄ‡∏ä‡∏¥‡∏ç‡∏ä‡∏ß‡∏ô', 'O'),\n",
              " ('‡∏ú‡∏π‡πâ', 'O'),\n",
              " ('‡∏™‡∏ô‡πÉ‡∏à', 'O'),\n",
              " ('‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡πà‡∏ß‡∏°', 'O'),\n",
              " ('‡∏ü‡∏±‡∏á', 'O'),\n",
              " ('‡∏ö‡∏£‡∏£‡∏¢‡∏≤‡∏¢', 'O'),\n",
              " ('‡∏û‡∏¥‡πÄ‡∏®‡∏©', 'O'),\n",
              " (' ', 'O'),\n",
              " ('\\n', 'O'),\n",
              " ('‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á', 'O'),\n",
              " (' ', 'O'),\n",
              " ('‚Äú', 'O'),\n",
              " ('‡∏Å‡∏≤‡∏£', 'O'),\n",
              " ('‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå', 'O'),\n",
              " ('‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå', 'O'),\n",
              " ('‡∏†‡∏≤‡∏¢‡πÉ‡∏ô', 'O'),\n",
              " ('‡∏õ‡∏£‡∏¥', 'O'),\n",
              " ('‡∏à', 'O'),\n",
              " ('‡πÄ‡∏â‡∏ó', 'O'),\n",
              " ('‡πÅ‡∏ö‡∏ö', 'O'),\n",
              " ('‡∏≠‡∏±‡∏ï‡πÇ‡∏ô‡∏°‡∏±‡∏ï‡∏¥', 'O'),\n",
              " ('‡∏î‡πâ‡∏ß‡∏¢', 'O'),\n",
              " ('‡∏Å‡∏≤‡∏£‡∏à‡∏≥‡πÅ‡∏ô‡∏Å', 'O'),\n",
              " ('‡∏Ñ‡∏≥‡πÄ‡∏ä‡∏∑‡πà‡∏≠‡∏°', 'O'),\n",
              " ('‚Äù', 'O'),\n",
              " ('\\n', 'O'),\n",
              " ('‡πÇ‡∏î‡∏¢', 'O'),\n",
              " (' ', 'O'),\n",
              " ('‡∏î‡∏£.', 'B-PERSON'),\n",
              " ('‡∏≠‡∏£‡∏£‡∏ñ', 'I-PERSON'),\n",
              " ('‡∏û‡∏•', 'I-PERSON'),\n",
              " (' ', 'I-PERSON'),\n",
              " ('‡∏ò‡∏≥‡∏£‡∏á', 'I-PERSON'),\n",
              " ('‡∏£‡∏±‡∏ï‡∏ô', 'I-PERSON'),\n",
              " ('‡∏§‡∏ó‡∏ò‡∏¥‡πå', 'I-PERSON'),\n",
              " ('\\n', 'I-PERSON'),\n",
              " ('‡∏ß‡∏±‡∏ô', 'I-PERSON'),\n",
              " ('‡∏®‡∏∏‡∏Å‡∏£‡πå', 'I-PERSON'),\n",
              " ('‡∏ó‡∏µ‡πà', 'O'),\n",
              " (' ', 'O'),\n",
              " ('17', 'B-DATE'),\n",
              " (' ', 'I-DATE'),\n",
              " ('‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô', 'I-DATE'),\n",
              " (' ', 'I-DATE'),\n",
              " ('2560', 'I-DATE'),\n",
              " (' ', 'O'),\n",
              " ('‡πÄ‡∏ß‡∏•‡∏≤', 'O'),\n",
              " (' ', 'O'),\n",
              " ('13.30', 'B-TIME'),\n",
              " ('-', 'I-TIME'),\n",
              " ('14.30', 'I-TIME'),\n",
              " (' ', 'I-TIME'),\n",
              " ('‡∏ô.', 'I-TIME'),\n",
              " (' ', 'O'),\n",
              " ('‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏ô‡πÑ‡∏õ', 'O'),\n",
              " (' ', 'O'),\n",
              " ('‡∏ì', 'O'),\n",
              " (' ', 'O'),\n",
              " ('‡∏´‡πâ‡∏≠‡∏á', 'O'),\n",
              " (' ', 'O'),\n",
              " ('401', 'O'),\n",
              " ('/', 'O'),\n",
              " ('5', 'O'),\n",
              " (' ', 'O'),\n",
              " ('‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£', 'B-LOCATION'),\n",
              " ('‡∏°‡∏´‡∏≤', 'I-LOCATION'),\n",
              " ('‡∏à‡∏±‡∏Å‡∏£‡∏µ', 'I-LOCATION'),\n",
              " ('‡∏™‡∏¥‡∏£‡∏¥‡∏ô‡∏ò‡∏£', 'I-LOCATION'),\n",
              " (' ', 'O'),\n",
              " ('‡∏Ñ‡∏ì‡∏∞‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏®‡∏≤‡∏™‡∏ï‡∏£‡πå', 'O'),\n",
              " (' ', 'O'),\n",
              " ('‡∏à‡∏∏‡∏¨‡∏≤‡∏•‡∏á‡∏Å‡∏£‡∏ì‡πå', 'B-ORGANIZATION'),\n",
              " ('‡∏°‡∏´‡∏≤‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢', 'I-ORGANIZATION'),\n",
              " ('\\n', 'O'),\n",
              " ('‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°', 'O'),\n",
              " ('‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î', 'O'),\n",
              " ('‡πÄ‡∏û‡∏¥‡πà‡∏°‡πÄ‡∏ï‡∏¥‡∏°', 'O'),\n",
              " ('‡πÑ‡∏î‡πâ‡∏ó‡∏µ‡πà', 'O'),\n",
              " (' ', 'O'),\n",
              " ('0', 'B-PHONE'),\n",
              " ('-', 'I-PHONE'),\n",
              " ('2218', 'I-PHONE'),\n",
              " ('-', 'I-PHONE'),\n",
              " ('4692', 'I-PHONE'),\n",
              " ('\\n', 'I-PHONE')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK3rLhsrdCED",
        "colab_type": "text"
      },
      "source": [
        "#### Part of Speech (POS) Tags:\n",
        "\n",
        "\n",
        "Reference: [PUD Tags](https://universaldependencies.org/u/pos/all.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNrC5tYwdCED",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "|  Abbreviation |      Part-of-Speech tag    |            Examples             |       \n",
        "|---------------|----------------------------|---------------------------------|\n",
        "| ADJ           |  Adjective                 |    ‡πÉ‡∏´‡∏°‡πà, ‡∏û‡∏¥‡πÄ‡∏®‡∏© , ‡∏Å‡πà‡∏≠‡∏ô, ‡∏°‡∏≤‡∏Å, ‡∏™‡∏π‡∏á     |   \n",
        "| ADP           |  Adposition                |   ‡πÅ‡∏°‡πâ, ‡∏ß‡πà‡∏≤, ‡πÄ‡∏°‡∏∑‡πà‡∏≠, ‡∏Ç‡∏≠‡∏á, ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö       |   \n",
        "| ADV           |  Adverb                    |   ‡∏Å‡πà‡∏≠‡∏ô, ‡∏Å‡πá, ‡πÄ‡∏•‡πá‡∏Å‡∏ô‡πâ‡∏≠‡∏¢, ‡πÄ‡∏•‡∏¢, ‡∏™‡∏∏‡∏î       |   \n",
        "| AUX           |  Auxiliary                 |   ‡πÄ‡∏õ‡πá‡∏ô, ‡πÉ‡∏ä‡πà, ‡∏Ñ‡∏∑‡∏≠, ‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢             |   \n",
        "| CCONJ         |  Coordinating conjunction  |   ‡πÅ‡∏ï‡πà, ‡πÅ‡∏•‡∏∞, ‡∏´‡∏£‡∏∑‡∏≠                  |        \n",
        "| DET           |  Determiner                |   ‡∏ô‡∏µ‡πâ, ‡∏ô‡∏±‡πâ‡∏ô, ‡∏ó‡∏±‡πâ‡∏á, ‡πÄ‡∏û‡∏µ‡∏¢‡∏á, (‡∏´‡∏ô‡∏∂‡πà‡∏á)‡∏Ñ‡∏ô      |   \n",
        "| INTJ          |  Interjection              |   ‡∏≠‡∏∏‡πâ‡∏¢, ‡πÇ‡∏≠‡πâ‡∏¢                       |   \n",
        "| NOUN          |  Noun                      |   ‡∏Å‡∏≥‡∏°‡∏∑‡∏≠, ‡∏û‡∏ß‡∏Å, ‡∏™‡∏ô‡∏≤‡∏°, ‡∏Å‡∏µ‡∏¨‡∏≤, ‡∏ö‡∏±‡∏ç‡∏ä‡∏µ     |   \n",
        "| NUM           |  Numeral                   |   5,000, 103.7, 2004, ‡∏´‡∏ô‡∏∂‡πà‡∏á, ‡∏£‡πâ‡∏≠‡∏¢  |   \n",
        "| PART          |  Particle                  |   ‡∏°‡∏≤ ‡∏Ç‡∏∂‡πâ‡∏ô ‡πÑ‡∏°‡πà ‡πÑ‡∏î‡πâ ‡πÄ‡∏Ç‡πâ‡∏≤               |      \n",
        "| PRON          |  Pronoun                   |   ‡πÄ‡∏£‡∏≤, ‡πÄ‡∏Ç‡∏≤, ‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á, ‡πÉ‡∏Ñ‡∏£, ‡πÄ‡∏ò‡∏≠     |   \n",
        "| PROPN         |  Proper noun               |   ‡πÇ‡∏≠‡∏ö‡∏≤‡∏°‡∏≤, ‡πÅ‡∏Ñ‡∏õ‡∏¥‡∏ï‡∏≠‡∏•‡∏Æ‡∏¥‡∏•, ‡∏à‡∏µ‡πÇ‡∏≠‡∏û‡∏µ, ‡πÑ‡∏°‡πÄ‡∏Ñ‡∏¥‡∏• |   \n",
        "| PUNCT         |  Punctuation               |   (, ), \", ', :                 |    \n",
        "| SCONJ         |  Subordinating conjunction |    ‡∏´‡∏≤‡∏Å, ‡πÄ‡∏û‡πà‡∏£‡∏≤‡∏∞‡∏ß‡πà‡∏≤, ‡∏ñ‡πâ‡∏≤             |   \n",
        "| VERB          |  Verb                      |   ‡πÄ‡∏õ‡∏¥‡∏î, ‡πÉ‡∏´‡πâ, ‡πÉ‡∏ä‡πâ, ‡πÄ‡∏ú‡∏ä‡∏¥‡∏ç, ‡∏≠‡πà‡∏≤‡∏ô        |\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqe_2wv-dCEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pythainlp.tag import pos_tag"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoHmyaV0dCEF",
        "colab_type": "code",
        "colab": {},
        "outputId": "364c433c-9349-4fdc-de9a-059e48726917"
      },
      "source": [
        "\n",
        "sentence = \"‡∏â‡∏±‡∏ô‡πÑ‡∏õ‡πÄ‡∏î‡∏¥‡∏ô‡πÉ‡∏ô‡∏™‡∏ß‡∏ô‡∏™‡∏≤‡∏ò‡∏≤‡∏£‡∏ì‡∏∞\"\n",
        "tokens = word_tokenize(sentence, keep_whitespace=False)\n",
        "pos_tag(tokens, corpus=\"pud\", engine=\"perceptron\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('‡∏â‡∏±‡∏ô', 'PRON'),\n",
              " ('‡πÑ‡∏õ', 'VERB'),\n",
              " ('‡πÄ‡∏î‡∏¥‡∏ô', 'VERB'),\n",
              " ('‡πÉ‡∏ô', 'ADP'),\n",
              " ('‡∏™‡∏ß‡∏ô‡∏™‡∏≤‡∏ò‡∏≤‡∏£‡∏ì‡∏∞', 'NOUN')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miJKobw1dCEI",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "```\n",
        "Explaination:\n",
        "\n",
        "PRON = Pronoun \n",
        "\n",
        "VERB = Verb\n",
        "\n",
        "ADP = Adposition\n",
        "\n",
        "NOUN = Noun\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4Xa68kOdCEI",
        "colab_type": "code",
        "colab": {},
        "outputId": "8b6c48d0-c46c-408e-a199-8494ca2a8238"
      },
      "source": [
        "\n",
        "sentence = \"‡∏â‡∏±‡∏ô‡πÑ‡∏õ‡πÄ‡∏î‡∏¥‡∏ô‡πÉ‡∏ô‡∏™‡∏ß‡∏ô‡∏™‡∏≤‡∏ò‡∏≤‡∏£‡∏ì‡∏∞\"\n",
        "tokens = word_tokenize(sentence, keep_whitespace=False)\n",
        "pos_tag(tokens, corpus=\"orchid\", engine=\"perceptron\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('‡∏â‡∏±‡∏ô', 'PPRS'),\n",
              " ('‡πÑ‡∏õ', 'VACT'),\n",
              " ('‡πÄ‡∏î‡∏¥‡∏ô', 'VACT'),\n",
              " ('‡πÉ‡∏ô', 'RPRE'),\n",
              " ('‡∏™‡∏ß‡∏ô‡∏™‡∏≤‡∏ò‡∏≤‡∏£‡∏ì‡∏∞', 'NCMN')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A3ZUYnMdCEK",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "Explaination:\n",
        "\n",
        "PPRS = Personal pronoun \n",
        "\n",
        "VACT = Active verb\n",
        "\n",
        "RPRE = Preposition\n",
        "\n",
        "NCMN = Common noun\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uznIH98dCEL",
        "colab_type": "text"
      },
      "source": [
        "#### __Question 6:__ From the following setentences what are the POS tags (based on UD)\n",
        "\n",
        "\n",
        "```text\n",
        "‡∏´‡∏°‡∏≤ ‡πÅ‡∏•‡∏∞ ‡πÅ‡∏°‡∏ß ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Å‡∏¥‡∏ô ‡∏≠‡∏≤‡∏´‡∏≤‡∏£\n",
        "```\n",
        "\n",
        "\n",
        "Hint: Here is the list of POS tags of this sentence.\n",
        "\n",
        "- NOUN = Noun\n",
        "- CCONJ = Coordinating Conjunction\n",
        "- VERB = Active Verb\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRWMoplzdCEL",
        "colab_type": "code",
        "colab": {},
        "outputId": "217a92d9-b4a4-483d-95b4-301b9c91805a"
      },
      "source": [
        "# Run this block to see the result\n",
        "\n",
        "sentence = \"‡∏´‡∏°‡∏≤‡πÅ‡∏•‡∏∞‡πÅ‡∏°‡∏ß‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Å‡∏¥‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£\"\n",
        "tokens = word_tokenize(sentence, keep_whitespace=False)\n",
        "pos_tag(tokens, corpus=\"ud\", engine=\"perceptron\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('‡∏´‡∏°‡∏≤', 'NOUN'),\n",
              " ('‡πÅ‡∏•‡∏∞', 'CCONJ'),\n",
              " ('‡πÅ‡∏°‡∏ß', 'NOUN'),\n",
              " ('‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Å‡∏¥‡∏ô', 'VERB'),\n",
              " ('‡∏≠‡∏≤‡∏´‡∏≤‡∏£', 'NOUN')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nvLRzpOdCEN",
        "colab_type": "text"
      },
      "source": [
        "#### __Question 7:__ From the following setentences what are the POS tags (based on Orchid)\n",
        "\n",
        "\n",
        "```text\n",
        "‡∏´‡∏°‡∏≤ ‡πÅ‡∏•‡∏∞ ‡πÅ‡∏°‡∏ß ‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Å‡∏¥‡∏ô ‡∏≠‡∏≤‡∏´‡∏≤‡∏£\n",
        "```\n",
        "\n",
        "Hint: Here is the list of POS tags of this sentence.\n",
        "\n",
        "- NCMN = Common Noun\n",
        "- JCRG = Coordinating Conjunction\n",
        "- VACT = Active Verb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCPgwliIdCEN",
        "colab_type": "code",
        "colab": {},
        "outputId": "4075ae55-62b8-4e34-e44a-809cc71e6d42"
      },
      "source": [
        "# Run this block to see the result\n",
        "\n",
        "sentence = \"‡∏´‡∏°‡∏≤‡πÅ‡∏•‡∏∞‡πÅ‡∏°‡∏ß‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Å‡∏¥‡∏ô‡∏≠‡∏≤‡∏´‡∏≤‡∏£\"\n",
        "tokens = word_tokenize(sentence, keep_whitespace=False)\n",
        "pos_tag(tokens, corpus=\"orchid\", engine=\"perceptron\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('‡∏´‡∏°‡∏≤', 'NCMN'),\n",
              " ('‡πÅ‡∏•‡∏∞', 'JCRG'),\n",
              " ('‡πÅ‡∏°‡∏ß', 'NCMN'),\n",
              " ('‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Å‡∏¥‡∏ô', 'VACT'),\n",
              " ('‡∏≠‡∏≤‡∏´‡∏≤‡∏£', 'NCMN')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYkg6VTAdCEP",
        "colab_type": "text"
      },
      "source": [
        "## 3. Spell checking\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Pthc3PFdCEQ",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 PyThaiNLP's spell checker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDJn_ijcdCEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pythainlp.spell import correct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFP4XeJ5dCES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mispelled_words = [\n",
        "    \"‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏ô\",\n",
        "    \"‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏¥\",\n",
        "    \"‡∏õ‡∏£‡∏∞‡∏ò‡∏≤‡∏£‡∏≤‡∏ò‡∏¥‡∏õ‡∏î‡∏µ\",\n",
        "    \"‡∏™‡∏±‡∏õ‡∏õ‡∏∞‡∏£‡∏î\",\n",
        "    \"‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡∏∏\",\n",
        "    \"‡πÄ‡∏´‡∏ï‡∏Å‡∏≤‡∏£‡∏ì‡πå\",\n",
        "    \"‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡∏¥\",\n",
        "    \"‡∏ù‡∏±‡∏Å‡πÑ‡∏ù‡πà\",\n",
        "    \"‡∏ô‡∏≤‡∏¢‡∏Å‡∏£‡∏±‡∏ç‡∏°‡∏ô‡∏ï‡∏µ\"\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4pJBox4dCET",
        "colab_type": "code",
        "colab": {},
        "outputId": "c636851f-e2f6-437c-f83a-52b4e4a4d224"
      },
      "source": [
        "for word in mispelled_words:\n",
        "    print(\"{} -> {}\".format(word, correct(word)))\n",
        "    print(\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏ô -> ‡πÇ‡∏£‡∏á‡∏û‡∏¢‡∏≤‡∏ö‡∏≤‡∏•\n",
            "\n",
            "‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏¥ -> ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ\n",
            "\n",
            "‡∏õ‡∏£‡∏∞‡∏ò‡∏≤‡∏£‡∏≤‡∏ò‡∏¥‡∏õ‡∏î‡∏µ -> ‡∏õ‡∏£‡∏∞‡∏ò‡∏≤‡∏ô‡∏≤‡∏ò‡∏¥‡∏ö‡∏î‡∏µ\n",
            "\n",
            "‡∏™‡∏±‡∏õ‡∏õ‡∏∞‡∏£‡∏î -> ‡∏™‡∏±‡∏ö‡∏õ‡∏∞‡∏£‡∏î\n",
            "\n",
            "‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡∏∏ -> ‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï\n",
            "\n",
            "‡πÄ‡∏´‡∏ï‡∏Å‡∏≤‡∏£‡∏ì‡πå -> ‡πÄ‡∏´‡∏ï‡∏∏‡∏Å‡∏≤‡∏£‡∏ì‡πå\n",
            "\n",
            "‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï‡∏¥ -> ‡∏≠‡∏ô‡∏∏‡∏ç‡∏≤‡∏ï\n",
            "\n",
            "‡∏ù‡∏±‡∏Å‡πÑ‡∏ù‡πà -> ‡∏ù‡∏±‡∏Å‡πÉ‡∏ù‡πà\n",
            "\n",
            "‡∏ô‡∏≤‡∏¢‡∏Å‡∏£‡∏±‡∏ç‡∏°‡∏ô‡∏ï‡∏µ -> ‡∏ô‡∏≤‡∏¢‡∏Å‡∏£‡∏±‡∏ê‡∏°‡∏ô‡∏ï‡∏£‡∏µ\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKNUmGRfdCEU",
        "colab_type": "text"
      },
      "source": [
        "__Try out:__ Put any mispelling words and correct them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DN-yStWdCEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct(\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7CQfZN5dCEW",
        "colab_type": "text"
      },
      "source": [
        "## 4. Utility functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bz20hXJ4dCEW",
        "colab_type": "text"
      },
      "source": [
        "### 4.1 Thai digits and currency Conversion\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFr1uvPkdCEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pythainlp.util import (\n",
        "    thai_digit_to_arabic_digit,\n",
        "    arabic_digit_to_thai_digit,\n",
        "    bahttext,\n",
        "    digit_to_text,\n",
        "    thaiword_to_num)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veW6IxltdCEY",
        "colab_type": "code",
        "colab": {},
        "outputId": "05d1bbc7-3587-45e5-9097-c581d19d751a"
      },
      "source": [
        "thai_digit_to_arabic_digit(\"‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà ‡πì‡πë ‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏° ‡πí‡πï‡πñ‡πí ‡πÄ‡∏ß‡∏•‡∏≤ ‡πë‡πì:‡πê‡πê ‡∏ô. ‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 31 ‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏° 2562 ‡πÄ‡∏ß‡∏•‡∏≤ 13:00 ‡∏ô. ‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lHlVCVbdCEa",
        "colab_type": "code",
        "colab": {},
        "outputId": "7f86dbb8-f5fe-4f85-f902-bca62ffa2403"
      },
      "source": [
        "arabic_digit_to_thai_digit(\"‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà 31 ‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°2562 ‡πÄ‡∏ß‡∏•‡∏≤ 13:00 ‡∏ô. ‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ß‡∏±‡∏ô‡∏ó‡∏µ‡πà ‡πì‡πë ‡∏ï‡∏∏‡∏•‡∏≤‡∏Ñ‡∏°‡πí‡πï‡πñ‡πí ‡πÄ‡∏ß‡∏•‡∏≤ ‡πë‡πì:‡πê‡πê ‡∏ô. ‡∏ï‡∏≤‡∏°‡πÄ‡∏ß‡∏•‡∏≤‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡πÑ‡∏ó‡∏¢'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRQ4v3rRdCEc",
        "colab_type": "code",
        "colab": {},
        "outputId": "13b8bb89-fd12-468e-bcb2-8b46a8c6b4c6"
      },
      "source": [
        "bahttext(1234.24)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏û‡∏±‡∏ô‡∏™‡∏≠‡∏á‡∏£‡πâ‡∏≠‡∏¢‡∏™‡∏≤‡∏°‡∏™‡∏¥‡∏ö‡∏™‡∏µ‡πà‡∏ö‡∏≤‡∏ó‡∏¢‡∏µ‡πà‡∏™‡∏¥‡∏ö‡∏™‡∏µ‡πà‡∏™‡∏ï‡∏≤‡∏á‡∏Ñ‡πå'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFWhAMO9dCEe",
        "colab_type": "code",
        "colab": {},
        "outputId": "70172fe5-5bac-46a9-a7f4-5d7cb52f2299"
      },
      "source": [
        "bahttext(21)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'‡∏¢‡∏µ‡πà‡∏™‡∏¥‡∏ö‡πÄ‡∏≠‡πá‡∏î‡∏ö‡∏≤‡∏ó‡∏ñ‡πâ‡∏ß‡∏ô'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFU8b2CidCEf",
        "colab_type": "code",
        "colab": {},
        "outputId": "d19f5de8-164b-4406-a861-914873c4a2b1"
      },
      "source": [
        "bahttext(240000000000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'‡∏™‡∏≠‡∏á‡πÅ‡∏™‡∏ô‡∏™‡∏µ‡πà‡∏´‡∏°‡∏∑‡πà‡∏ô‡∏•‡πâ‡∏≤‡∏ô‡∏ö‡∏≤‡∏ó‡∏ñ‡πâ‡∏ß‡∏ô'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWJ-00FtdCEg",
        "colab_type": "code",
        "colab": {},
        "outputId": "717a3edd-e798-4b4b-9e23-967e4ef1fbf0"
      },
      "source": [
        "thaiword_to_num(\"‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏£‡πâ‡∏≠‡∏¢\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGGLibyMdCEh",
        "colab_type": "code",
        "colab": {},
        "outputId": "0d768479-b61f-46a3-cf8b-48dfa5c1f716"
      },
      "source": [
        "digit_to_text(\"‡πì ‡∏£‡πâ‡∏≠‡∏¢‡∏•‡πâ‡∏≤‡∏ô\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'‡∏™‡∏≤‡∏° ‡∏£‡πâ‡∏≠‡∏¢‡∏•‡πâ‡∏≤‡∏ô'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4czXmaMdCEj",
        "colab_type": "code",
        "colab": {},
        "outputId": "498c69d9-cf5c-4e6c-f7d4-4bc8134f9613"
      },
      "source": [
        "digit_to_text(\"‡πì‡πë\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'‡∏™‡∏≤‡∏°‡∏´‡∏ô‡∏∂‡πà‡∏á'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVmE2-QcdCEl",
        "colab_type": "code",
        "colab": {},
        "outputId": "07b0e77b-9560-4030-e84d-ac9c6741fbc4"
      },
      "source": [
        "thaiword_to_num(\"‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏û‡∏±‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SREyVYJddCEn",
        "colab_type": "code",
        "colab": {},
        "outputId": "a1a85f3f-b587-4904-88f2-a8bd198032c2"
      },
      "source": [
        "thaiword_to_num(\"‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏•‡πâ‡∏≤‡∏ô‡∏´‡∏Å‡∏™‡∏¥‡∏ö‡πÄ‡∏≠‡πá‡∏î\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000061"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTBFaZJJdCEo",
        "colab_type": "code",
        "colab": {},
        "outputId": "c696793a-3c4b-4557-b855-4dd5c5b2fd3a"
      },
      "source": [
        "thaiword_to_num(\"‡∏û‡∏±‡∏ô‡∏•‡πâ‡∏≤‡∏ô\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQsGtS0tdCEq",
        "colab_type": "text"
      },
      "source": [
        "#### __Question 8 :__ Given a text representing an amont money, convert into number.\n",
        "\n",
        "```\n",
        "‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏≤‡∏ã‡∏∂‡πà‡∏á‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì ‡πë‡πí,‡πï‡πê‡πê ‡∏•‡πâ‡∏≤‡∏ô‡∏î‡∏≠‡∏•‡∏•‡∏≤‡∏£‡πå‡∏™‡∏´‡∏£‡∏±‡∏ê ‡πÉ‡∏´‡πâ‡∏ó‡∏ß‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏õ‡πá‡∏ô ‡πì ‡∏´‡∏°‡∏∑‡πà‡∏ô‡∏•‡πâ‡∏≤‡∏ô\n",
        "```\n",
        "->\n",
        "```\n",
        "‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏≤‡∏ã‡∏∂‡πà‡∏á‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 12,500 ‡∏•‡πâ‡∏≤‡∏ô‡∏î‡∏≠‡∏•‡∏•‡∏≤‡∏£‡πå‡∏™‡∏´‡∏£‡∏±‡∏ê ‡πÉ‡∏´‡πâ‡∏ó‡∏ß‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏õ‡πá‡∏ô 3 ‡∏´‡∏°‡∏∑‡πà‡∏ô‡∏•‡πâ‡∏≤‡∏ô\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiWHIGGEdCEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_with_thai_digits = \"‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏≤‡∏ã‡∏∂‡πà‡∏á‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì ‡πë‡πí,‡πï‡πê‡πê ‡∏•‡πâ‡∏≤‡∏ô‡∏î‡∏≠‡∏•‡∏•‡∏≤‡∏£‡πå‡∏™‡∏´‡∏£‡∏±‡∏ê ‡πÉ‡∏´‡πâ‡∏ó‡∏ß‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏õ‡πá‡∏ô ‡πì ‡∏´‡∏°‡∏∑‡πà‡∏ô‡∏•‡πâ‡∏≤‡∏ô\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYPtRi3pdCEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(text):\n",
        "    splits = text.split(\" \")\n",
        "    \n",
        "    for index, split in enumerate(splits):\n",
        "        \n",
        "        if re.search(r\"[‡πê-‡πô]\", split):\n",
        "            print(\"\\nselcted split: \", split)\n",
        "            ## Modify the following line to convert from thai digits to arabic\n",
        "\n",
        "            splits[index] = split\n",
        "            \n",
        "            ##--------------------- ##\n",
        "            print(\"convert to: \", splits[index])\n",
        "    \n",
        "    return \" \".join(splits)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrVnG502dCEt",
        "colab_type": "code",
        "colab": {},
        "outputId": "a8df30ad-6611-4737-f994-7299f25bb012"
      },
      "source": [
        "convert(text_with_thai_digits)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "selcted split:  ‡πë‡πí,‡πï‡πê‡πê\n",
            "convert to:  ‡πë‡πí,‡πï‡πê‡πê\n",
            "\n",
            "selcted split:  ‡πì\n",
            "convert to:  ‡πì\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏≤‡∏ã‡∏∂‡πà‡∏á‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì ‡πë‡πí,‡πï‡πê‡πê ‡∏•‡πâ‡∏≤‡∏ô‡∏î‡∏≠‡∏•‡∏•‡∏≤‡∏£‡πå‡∏™‡∏´‡∏£‡∏±‡∏ê ‡πÉ‡∏´‡πâ‡∏ó‡∏ß‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏õ‡πá‡∏ô ‡πì ‡∏´‡∏°‡∏∑‡πà‡∏ô‡∏•‡πâ‡∏≤‡∏ô'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2uTItrKdCEu",
        "colab_type": "text"
      },
      "source": [
        "__Test:__ Given a list of sentences, please return only Thai sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4fFB3-rdCEv",
        "colab_type": "code",
        "colab": {},
        "outputId": "61becbba-d995-4cfd-e398-f6567eae638f"
      },
      "source": [
        "def test_convert_thai_digits(convert):\n",
        "    expect = \"‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏≤‡∏ã‡∏∂‡πà‡∏á‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì 12,500 ‡∏•‡πâ‡∏≤‡∏ô‡∏î‡∏≠‡∏•‡∏•‡∏≤‡∏£‡πå‡∏™‡∏´‡∏£‡∏±‡∏ê ‡πÉ‡∏´‡πâ‡∏ó‡∏ß‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏õ‡πá‡∏ô 3 ‡∏´‡∏°‡∏∑‡πà‡∏ô‡∏•‡πâ‡∏≤‡∏ô\"\n",
        "    actual = convert(text_with_thai_digits)\n",
        "\n",
        "    if actual == expect:\n",
        "        print(\"‚úÖ Test succeed. üòÅ\")\n",
        "    else:\n",
        "        print(\"‚ùå Test failed. üò≠\")\n",
        "        print(\"The actual results:\", actual)\n",
        "\n",
        "test_convert_thai_digits(convert)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "selcted split:  ‡πë‡πí,‡πï‡πê‡πê\n",
            "convert to:  ‡πë‡πí,‡πï‡πê‡πê\n",
            "\n",
            "selcted split:  ‡πì\n",
            "convert to:  ‡πì\n",
            "‚ùå Test failed. üò≠\n",
            "The actual results: ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏°‡∏π‡∏•‡∏Ñ‡πà‡∏≤‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏≤‡∏ã‡∏∂‡πà‡∏á‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô‡∏°‡∏µ‡∏õ‡∏£‡∏∞‡∏°‡∏≤‡∏ì ‡πë‡πí,‡πï‡πê‡πê ‡∏•‡πâ‡∏≤‡∏ô‡∏î‡∏≠‡∏•‡∏•‡∏≤‡∏£‡πå‡∏™‡∏´‡∏£‡∏±‡∏ê ‡πÉ‡∏´‡πâ‡∏ó‡∏ß‡∏µ‡∏Ç‡∏∂‡πâ‡∏ô‡πÄ‡∏õ‡πá‡∏ô ‡πì ‡∏´‡∏°‡∏∑‡πà‡∏ô‡∏•‡πâ‡∏≤‡∏ô\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R0mdTYjdCEw",
        "colab_type": "text"
      },
      "source": [
        "__Solution:__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1at31RndCEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(text):\n",
        "    splits = text.split(\" \")\n",
        "    \n",
        "    for index, split in enumerate(splits):\n",
        "        \n",
        "        if re.search(r\"[‡πê-‡πô]\", split):\n",
        "            print(\"\\nselcted split: \", split)\n",
        "            ## Write the code to convert\n",
        "\n",
        "            splits[index] = thai_digit_to_arabic_digit(split)\n",
        "            \n",
        "            \n",
        "            print(\"convert to: \", splits[index])\n",
        "\n",
        "    return \" \".join(splits)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ji5J62zJdCEy",
        "colab_type": "code",
        "colab": {},
        "outputId": "27304981-c83c-4d05-aefc-038a9aa42a9a"
      },
      "source": [
        "test_convert_thai_digits(convert)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "selcted split:  ‡πë‡πí,‡πï‡πê‡πê\n",
            "convert to:  12,500\n",
            "\n",
            "selcted split:  ‡πì\n",
            "convert to:  3\n",
            "‚úÖ Test succeed. üòÅ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W62wyBakdCEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDaHyLEwdCE0",
        "colab_type": "text"
      },
      "source": [
        "### 4.2 Thai Word count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZWfz6dIdCE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pythainlp.util import countthai\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLkOneJmdCE2",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Count percentage of Thai chacters in a text.\n",
        "\n",
        "```python\n",
        " countthai(text:str) -> percentage:float\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OoPKZ-TdCE3",
        "colab_type": "code",
        "colab": {},
        "outputId": "49955d70-3925-43c6-c517-ea8097a39195"
      },
      "source": [
        "countthai(\"Hello world.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqDexyU4dCE4",
        "colab_type": "code",
        "colab": {},
        "outputId": "9f216182-597b-4596-97b7-36bddd6985dc"
      },
      "source": [
        "countthai(\"‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ ‡∏â‡∏±‡∏ô‡∏ä‡∏≠‡∏ö‡∏ô‡∏±‡πà‡∏á‡∏£‡∏ñ‡πÑ‡∏ü\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaA75gKwdCE5",
        "colab_type": "code",
        "colab": {},
        "outputId": "3e160ac0-aafe-4f70-8eda-544e062ea192"
      },
      "source": [
        "countthai(\"‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ Jane Doe\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46.15384615384615"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPZ8Pj3odCE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AY48u8z7dCE8",
        "colab_type": "text"
      },
      "source": [
        "#### __Question 9:__ Given a list of sentences, please return only Thai sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0k-NkTqdCE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "en_th_sentences = [\n",
        "    \"‡∏°‡∏±‡∏ô‡∏à‡∏∞‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ ‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÑ‡∏î‡πâ‡∏•‡πà‡∏∞?\",\n",
        "    \"‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ... ...‡∏î‡∏¥‡πä‡∏Å\",\n",
        "    \"# Just to get a glimpse beyond this illusion #\",\n",
        "    \"# I was soaring ever higher #\",\n",
        "    \"# but I flew too high #\",\n",
        "    \"    ‡πÉ‡∏ä‡πà\",\n",
        "    \"‡πÉ‡∏ä‡πà ‡πÄ‡∏Ç‡∏≤‡πÅ‡∏•‡∏∞‡πÅ‡∏ü‡∏£‡∏á‡∏Ñ‡πå ‡πÅ‡∏•‡∏∞ ‡πÅ‡∏Ñ‡∏™ ‡∏ñ‡πâ‡∏≤‡∏Ç‡∏ß‡∏î‡πÄ‡∏´‡∏•‡πâ‡∏≤‡πÄ‡∏Ç‡∏≤ ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Å‡∏£‡∏∞‡πÄ‡∏õ‡πã‡∏≤\",\n",
        "    \"‡∏°‡∏±‡∏ô‡∏Å‡πá‡∏î‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏≤‡∏ß‡∏•‡∏µ‡∏¢‡πå ‡∏°‡∏≤‡∏≠‡∏¢‡∏π‡πà‡∏ù‡∏±‡πà‡∏á‡πÄ‡∏£‡∏≤‡∏ñ‡∏π‡∏Å‡∏°‡∏±‡πâ‡∏¢?\",\n",
        "    \"‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏£‡∏≤‡∏ß‡∏•‡∏µ‡∏¢‡πå ‡πÄ‡∏£‡∏≤‡∏°‡∏µ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ï‡πâ‡∏≠‡∏á‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ô‡πÄ‡∏¢‡∏≠‡∏∞‡πÄ‡∏•‡∏¢\",\n",
        "    \"‡πÄ‡∏ä‡∏¥‡∏ç‡∏ô‡∏±‡πà‡∏á\",\n",
        "    \"== sync, corrected by elderman ==\",\n",
        "    \"# though my eyes could see, I still was a blind man #\",\n",
        "    \"# though my mind could think, I still was a madman #\",\n",
        "    \"‡πÑ‡∏î‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤ ‡∏û‡∏ß‡∏Å‡∏°‡∏±‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏°‡∏≤‡∏ï‡∏≤‡∏°‡∏•‡πà‡∏≤‡πÄ‡∏Ç‡∏≤\",\n",
        "    \"# I hear the voices when I'm dreaming #\",\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-QEVb62dCE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_thai_sentence(sentence):\n",
        "\n",
        "    ## Write down the code, to return value True if the sentence is in Thai language\n",
        "    \n",
        "    \n",
        "    \n",
        "    ##\n",
        "    return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11rdBna6dCE_",
        "colab_type": "text"
      },
      "source": [
        "__Test:__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlCh_khkdCE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "th_sentences = [\n",
        "    \"‡∏°‡∏±‡∏ô‡∏à‡∏∞‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ ‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÑ‡∏î‡πâ‡∏•‡πà‡∏∞?\",\n",
        "    \"‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ... ...‡∏î‡∏¥‡πä‡∏Å\",\n",
        "    \"    ‡πÉ‡∏ä‡πà\",\n",
        "    \"‡πÉ‡∏ä‡πà ‡πÄ‡∏Ç‡∏≤‡πÅ‡∏•‡∏∞‡πÅ‡∏ü‡∏£‡∏á‡∏Ñ‡πå ‡πÅ‡∏•‡∏∞ ‡πÅ‡∏Ñ‡∏™ ‡∏ñ‡πâ‡∏≤‡∏Ç‡∏ß‡∏î‡πÄ‡∏´‡∏•‡πâ‡∏≤‡πÄ‡∏Ç‡∏≤ ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Å‡∏£‡∏∞‡πÄ‡∏õ‡πã‡∏≤\",\n",
        "    \"‡∏°‡∏±‡∏ô‡∏Å‡πá‡∏î‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏≤‡∏ß‡∏•‡∏µ‡∏¢‡πå ‡∏°‡∏≤‡∏≠‡∏¢‡∏π‡πà‡∏ù‡∏±‡πà‡∏á‡πÄ‡∏£‡∏≤‡∏ñ‡∏π‡∏Å‡∏°‡∏±‡πâ‡∏¢?\",\n",
        "    \"‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏£‡∏≤‡∏ß‡∏•‡∏µ‡∏¢‡πå ‡πÄ‡∏£‡∏≤‡∏°‡∏µ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ï‡πâ‡∏≠‡∏á‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ô‡πÄ‡∏¢‡∏≠‡∏∞‡πÄ‡∏•‡∏¢\",\n",
        "    \"‡πÄ‡∏ä‡∏¥‡∏ç‡∏ô‡∏±‡πà‡∏á\",\n",
        "    \"‡πÑ‡∏î‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤ ‡∏û‡∏ß‡∏Å‡∏°‡∏±‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏°‡∏≤‡∏ï‡∏≤‡∏°‡∏•‡πà‡∏≤‡πÄ‡∏Ç‡∏≤\",\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOXQEQYQdCFA",
        "colab_type": "code",
        "colab": {},
        "outputId": "3777d85d-c861-48a8-93ca-fea879371aa6"
      },
      "source": [
        "actual = list(filter(test_thai_sentence, en_th_sentences))\n",
        "expect = th_sentences\n",
        "\n",
        "if actual == expect:\n",
        "    print(\"‚úÖ Test succeed. üòÅ\")\n",
        "else:\n",
        "    print(\"‚ùå Test failed. üò≠\")\n",
        "    print(\"The actual results:\", actual)\n",
        "    print(\"\\nThe expected sentences to be returned:\\n\")\n",
        "    for i, sentence in enumerate(th_sentences):\n",
        "        print(i+1, sentence)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "‚ùå Test failed. üò≠\n",
            "The actual results: []\n",
            "\n",
            "The expected sentences to be returned:\n",
            "\n",
            "1 ‡∏°‡∏±‡∏ô‡∏à‡∏∞‡∏°‡∏µ‡∏≠‡∏∞‡πÑ‡∏£‡∏ó‡∏µ‡πà‡∏ó‡∏≥‡πÉ‡∏´‡πâ ‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î‡πÑ‡∏î‡πâ‡∏•‡πà‡∏∞?\n",
            "2 ‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ... ...‡∏î‡∏¥‡πä‡∏Å\n",
            "3     ‡πÉ‡∏ä‡πà\n",
            "4 ‡πÉ‡∏ä‡πà ‡πÄ‡∏Ç‡∏≤‡πÅ‡∏•‡∏∞‡πÅ‡∏ü‡∏£‡∏á‡∏Ñ‡πå ‡πÅ‡∏•‡∏∞ ‡πÅ‡∏Ñ‡∏™ ‡∏ñ‡πâ‡∏≤‡∏Ç‡∏ß‡∏î‡πÄ‡∏´‡∏•‡πâ‡∏≤‡πÄ‡∏Ç‡∏≤ ‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Å‡∏£‡∏∞‡πÄ‡∏õ‡πã‡∏≤\n",
            "5 ‡∏°‡∏±‡∏ô‡∏Å‡πá‡∏î‡∏µ‡∏ó‡∏µ‡πà‡πÄ‡∏£‡∏≤‡πÑ‡∏î‡πâ‡∏Ñ‡∏£‡∏≤‡∏ß‡∏•‡∏µ‡∏¢‡πå ‡∏°‡∏≤‡∏≠‡∏¢‡∏π‡πà‡∏ù‡∏±‡πà‡∏á‡πÄ‡∏£‡∏≤‡∏ñ‡∏π‡∏Å‡∏°‡∏±‡πâ‡∏¢?\n",
            "6 ‡∏Ñ‡∏∏‡∏ì‡∏Ñ‡∏£‡∏≤‡∏ß‡∏•‡∏µ‡∏¢‡πå ‡πÄ‡∏£‡∏≤‡∏°‡∏µ‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏á‡∏ï‡πâ‡∏≠‡∏á‡∏Ñ‡∏∏‡∏¢‡∏Å‡∏±‡∏ô‡πÄ‡∏¢‡∏≠‡∏∞‡πÄ‡∏•‡∏¢\n",
            "7 ‡πÄ‡∏ä‡∏¥‡∏ç‡∏ô‡∏±‡πà‡∏á\n",
            "8 ‡πÑ‡∏î‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏ß‡πà‡∏≤ ‡∏û‡∏ß‡∏Å‡∏°‡∏±‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏°‡∏≤‡∏ï‡∏≤‡∏°‡∏•‡πà‡∏≤‡πÄ‡∏Ç‡∏≤\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYIZrf32dCFB",
        "colab_type": "text"
      },
      "source": [
        "__Solution:__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUq5ZZFJdCFC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_thai_sentence(sentence):\n",
        "\n",
        "    ## Write down the code, to return value True if the sentence is in Thai language\n",
        "    \n",
        "    if countthai(sentence)  >= 90.0:\n",
        "        return True\n",
        "    \n",
        "    ##\n",
        "    return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSVGJnsbdCFD",
        "colab_type": "code",
        "colab": {},
        "outputId": "58c41e3c-6b39-4295-c1b5-ca768048087d"
      },
      "source": [
        "actual = list(filter(test_thai_sentence, en_th_sentences))\n",
        "expect = th_sentences\n",
        "\n",
        "if actual == expect:\n",
        "    print(\"‚úÖ Test succeed. üòÅ\")\n",
        "else:\n",
        "    print(\"‚ùå Test failed. üò≠\")\n",
        "    print(\"The actual results:\", actual)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "‚úÖ Test succeed. üòÅ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WP5qhl8kdCFE",
        "colab_type": "text"
      },
      "source": [
        "### 4.3 Data and time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hSuVEn8dCFE",
        "colab_type": "text"
      },
      "source": [
        "This function uses Thai names and Thai Buddhist Era for these directives:\n",
        "\n",
        "- __%a__ - abbreviated weekday name (e.g. ‚Äú‡∏à‚Äù, ‚Äú‡∏≠‚Äù, ‚Äú‡∏û‚Äù, ‚Äú‡∏û‡∏§‚Äù, ‚Äú‡∏®‚Äù, ‚Äú‡∏™‚Äù, ‚Äú‡∏≠‡∏≤‚Äù)\n",
        "\n",
        "- __%A__ - full weekday name (e.g.‚Äú‡∏ß‡∏±‡∏ô‡∏à‡∏±‡∏ô‡∏ó‡∏£‡πå‚Äù, ‚Äú‡∏ß‡∏±‡∏ô‡∏≠‡∏±‡∏á‡∏Ñ‡∏≤‡∏£‚Äù, ‚Äú‡∏ß‡∏±‡∏ô‡πÄ‡∏™‡∏≤‡∏£‡πå‚Äù, ‚Äú‡∏ß‡∏±‡∏ô‡∏≠‡∏≤‡∏ó‡∏¥‡∏ï‡∏¢‡πå‚Äù)\n",
        "\n",
        "- __%b__ - abbreviated month name (e.g.‚Äú‡∏°.‡∏Ñ.‚Äù,‚Äù‡∏Å.‡∏û.‚Äù,‚Äù‡∏°‡∏µ.‡∏Ñ.‚Äù,‚Äù‡πÄ‡∏°.‡∏¢.‚Äù,‚Äù‡∏û.‡∏Ñ.‚Äù,‚Äù‡∏°‡∏¥.‡∏¢.‚Äù, ‚Äú‡∏ò.‡∏Ñ.‚Äù)\n",
        "\n",
        "- __%B__ - full month name (e.g. ‚Äú‡∏°‡∏Å‡∏£‡∏≤‡∏Ñ‡∏°‚Äù, ‚Äú‡∏Å‡∏∏‡∏°‡∏†‡∏≤‡∏û‡∏±‡∏ô‡∏ò‡πå‚Äù, ‚Äú‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô‚Äù, ‚Äú‡∏ò‡∏±‡∏ô‡∏ß‡∏≤‡∏Ñ‡∏°‚Äù,)\n",
        "\n",
        "- __%y__ - year without century (e.g. ‚Äú56‚Äù, ‚Äú10‚Äù)\n",
        "\n",
        "- __%Y__ - year with century (e.g. ‚Äú2556‚Äù, ‚Äú2410‚Äù)\n",
        "\n",
        "- __%c__ - date and time representation (e.g. ‚Äú‡∏û 6 ‡∏ï.‡∏Ñ. 01:40:00 2519‚Äù)\n",
        "\n",
        "- __%v__ - short date representation (e.g. ‚Äù 6-‡∏°.‡∏Ñ.-2562‚Äù, ‚Äú27-‡∏Å.‡∏û.-2555‚Äù)\n",
        "\n",
        "- __%d__ - day (e.g. \"01\", \"07\", 10\", \"31\")\n",
        "\n",
        "- __%-d__ - day with no zero padding (e.g. \"1\", \"7\",10\", \"31\")\n",
        " \n",
        "- __%H__  - hour (e.g. \"01\", \"06\", \"23\")\n",
        "\n",
        "- __%-H__ - hour with no zero padding (e.g. \"1\", \"6\", \"23\"))\n",
        "\n",
        "- __%M__  - minute (e.g. \"1\", \"2\", \"11\", \"12\")\n",
        "\n",
        "- __%S__  - second (e.g. \"1\", \"2\", \"11\", \"12\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bA0orfsdCFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime\n",
        "from pythainlp.util import thai_strftime\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJt_6vPvdCFH",
        "colab_type": "code",
        "colab": {},
        "outputId": "dfa525a7-a83b-4863-820f-01245b03970c"
      },
      "source": [
        "# Print the current date in Thai format\n",
        "\n",
        "thai_strftime(datetime.now(), \"%d %B %Y\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'01 ‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô 2562'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZvxDSw9dCFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qwqh8midCFK",
        "colab_type": "text"
      },
      "source": [
        "#### __Question 10:__ Given a date time object, return the datetime string in the following format\n",
        "\n",
        "\n",
        "```\n",
        "‡∏ß‡∏±‡∏ô‡∏®‡∏∏‡∏Å‡∏£‡πå ‡∏ó‡∏µ‡πà 1 ‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô ‡∏õ‡∏µ ‡∏û.‡∏®. 2562 ‡πÄ‡∏ß‡∏•‡∏≤ 11 ‡∏ô‡∏≤‡∏¨‡∏¥‡∏Å‡∏≤ 30 ‡∏ô‡∏≤‡∏ó‡∏µ 10 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx5rRluVdCFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datetime_object_workshop_day = datetime(year=2019, month=11, day=1,hour=11,minute=30,second=10)\n",
        "\n",
        "def print_datetime_thai(datetime_object):\n",
        "    # Write down the format string.\n",
        "    fmt = \"\"\n",
        "    return thai_strftime(datetime_object, fmt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcrXOGu7dCFM",
        "colab_type": "text"
      },
      "source": [
        "__Test:__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATOHHhVPdCFM",
        "colab_type": "code",
        "colab": {},
        "outputId": "e4c69c8b-2457-4a42-c3df-08985b20fc49"
      },
      "source": [
        "def test_print_datetime_thai(fn):\n",
        "    expect = \"‡∏ß‡∏±‡∏ô‡∏®‡∏∏‡∏Å‡∏£‡πå ‡∏ó‡∏µ‡πà 1 ‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô ‡∏û.‡∏®. 2562 ‡πÄ‡∏ß‡∏•‡∏≤ 11 ‡∏ô‡∏≤‡∏¨‡∏¥‡∏Å‡∏≤ 30 ‡∏ô‡∏≤‡∏ó‡∏µ 10 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\"\n",
        "    actual = fn(datetime_object_workshop_day)\n",
        "\n",
        "    if actual == expect:\n",
        "        print(\"‚úÖ Test succeed. üòÅ\\n\")\n",
        "        print(\"Your Result:\",expect)\n",
        "    else:\n",
        "        print(\"‚ùå Test failed. üò≠\")\n",
        "        print(\"\\nYour result    :\", actual)\n",
        "        print(\"\\nExpected result:\", expect)\n",
        "\n",
        "test_print_datetime_thai(print_datetime_thai)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "‚ùå Test failed. üò≠\n",
            "\n",
            "Your result    : \n",
            "\n",
            "Expected result: ‡∏ß‡∏±‡∏ô‡∏®‡∏∏‡∏Å‡∏£‡πå ‡∏ó‡∏µ‡πà 1 ‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô ‡∏û.‡∏®. 2562 ‡πÄ‡∏ß‡∏•‡∏≤ 11 ‡∏ô‡∏≤‡∏¨‡∏¥‡∏Å‡∏≤ 30 ‡∏ô‡∏≤‡∏ó‡∏µ 10 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGSWxv-DdCFO",
        "colab_type": "text"
      },
      "source": [
        "__Solution:__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mn9Pyp1dCFO",
        "colab_type": "code",
        "colab": {},
        "outputId": "3d54da7e-6b8b-474f-d42b-263b561592dc"
      },
      "source": [
        "def print_datetime_thai(datetime_object):\n",
        "    # Write down the format string.\n",
        "    fmt = \"%A ‡∏ó‡∏µ‡πà %-d %B ‡∏û.‡∏®. %Y ‡πÄ‡∏ß‡∏•‡∏≤ %H ‡∏ô‡∏≤‡∏¨‡∏¥‡∏Å‡∏≤ %M ‡∏ô‡∏≤‡∏ó‡∏µ %S ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\"\n",
        "    return thai_strftime(datetime_object, fmt)\n",
        "\n",
        "test_print_datetime_thai(print_datetime_thai)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "‚úÖ Test succeed. üòÅ\n",
            "\n",
            "Your Result: ‡∏ß‡∏±‡∏ô‡∏®‡∏∏‡∏Å‡∏£‡πå ‡∏ó‡∏µ‡πà 1 ‡∏û‡∏§‡∏®‡∏à‡∏¥‡∏Å‡∏≤‡∏¢‡∏ô ‡∏û.‡∏®. 2562 ‡πÄ‡∏ß‡∏•‡∏≤ 11 ‡∏ô‡∏≤‡∏¨‡∏¥‡∏Å‡∏≤ 30 ‡∏ô‡∏≤‡∏ó‡∏µ 10 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8V0SdzvdCFP",
        "colab_type": "text"
      },
      "source": [
        "__Without Thai strftime__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGYTLpnzdCFQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "2d80c310-dff3-4b6f-8e4f-04d6c279a693"
      },
      "source": [
        "datetime_object_workshop_day.strftime(\"%A ‡∏ó‡∏µ‡πà %-d %B ‡∏û.‡∏®. %Y ‡πÄ‡∏ß‡∏•‡∏≤ %H ‡∏ô‡∏≤‡∏¨‡∏¥‡∏Å‡∏≤ %M ‡∏ô‡∏≤‡∏ó‡∏µ %S ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Friday ‡∏ó‡∏µ‡πà 1 November ‡∏û.‡∏®. 2019 ‡πÄ‡∏ß‡∏•‡∏≤ 11 ‡∏ô‡∏≤‡∏¨‡∏¥‡∏Å‡∏≤ 30 ‡∏ô‡∏≤‡∏ó‡∏µ 10 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    }
  ]
}