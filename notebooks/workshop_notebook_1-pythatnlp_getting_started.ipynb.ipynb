{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "workshop_notebook_1-pythatnlp_getting_started.ipynb.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/korakot/pythainlp_workshop/blob/master/notebooks/workshop_notebook_1-pythatnlp_getting_started.ipynb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0AT0-j9pdCCc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "7f6c622a-3699-42e8-e25a-9c229a9d6f10"
      },
      "source": [
        "!pip install --upgrade --pre pythainlp "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pythainlp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cb/14/b80930a2cc09ed6b5f8a22da9be6ece56939839ae66d921d9c7123034ba0/pythainlp-2.1.4-py3-none-any.whl (11.1MB)\n",
            "\u001b[K     |████████████████████████████████| 11.1MB 2.9MB/s \n",
            "\u001b[?25hCollecting nltk>=3.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f6/1d/d925cfb4f324ede997f6d47bea4d9babba51b49e87a767c170b77005889d/nltk-3.4.5.zip (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 37.2MB/s \n",
            "\u001b[?25hCollecting tinydb>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/22/11/c3adfc1b367d1955461f82a4a0a8ffffd37b193e98f2fe89338cdd4a8a6a/tinydb-3.15.2-py2.py3-none-any.whl\n",
            "Collecting requests>=2.22.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/70/1935c770cb3be6e3a8b78ced23d7e0f3b187f5cbfab4749523ed65d7c9b1/requests-2.23.0-py2.py3-none-any.whl (58kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.5MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: tqdm>=4.1 in /usr/local/lib/python3.6/dist-packages (from pythainlp) (4.28.1)\n",
            "Requirement already satisfied, skipping upgrade: dill>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from pythainlp) (0.3.1.1)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.3->pythainlp) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.22.0->pythainlp) (2019.11.28)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.4.5-cp36-none-any.whl size=1449904 sha256=adc911e14eef9172e8734a261aec81be70b4f95c0bf169b5c26694b081fba00f\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/86/f6/68ab24c23f207c0077381a5e3904b2815136b879538a24b483\n",
            "Successfully built nltk\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement requests~=2.21.0, but you'll have requests 2.23.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: nltk, tinydb, requests, pythainlp\n",
            "  Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Found existing installation: requests 2.21.0\n",
            "    Uninstalling requests-2.21.0:\n",
            "      Successfully uninstalled requests-2.21.0\n",
            "Successfully installed nltk-3.4.5 pythainlp-2.1.4 requests-2.23.0 tinydb-3.15.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIRogXgddCCh",
        "colab_type": "text"
      },
      "source": [
        "# Workshop Notebook 1: Getting started with PyThaiNLP 😆\n",
        "\n",
        "\n",
        "Updated: 31 October 2019"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRhCNHVndCCi",
        "colab_type": "text"
      },
      "source": [
        "## Header\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBauTJuNdCCj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import Set, List\n",
        "from functools import reduce\n",
        "import re"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": false,
        "id": "TZdgP7sPdCCl",
        "colab_type": "text"
      },
      "source": [
        "## 1. Word Tokenization\n",
        "\n",
        "Word Tokenization is a process to determin word boundaries in a text or sentence.\n",
        "\n",
        "\n",
        "Given a sentence, the tokenizer then read the sentence and return a list of words (i.e. tokens).\n",
        "\n",
        "```python\n",
        "\n",
        "    definition: Tokenizer(str) -> List[str]\n",
        "    \n",
        "    \n",
        "    \n",
        "    Tokenizer(str:\"เธอคือ My Ambulance ของฉัน\")  -> List[\"เธอ\", \"คือ\", \"My\", \"Ambulance\", \"ของ\", \"ฉัน\"]\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": false,
        "id": "TpJpggrddCCm",
        "colab_type": "text"
      },
      "source": [
        "### Dictionary-based tokenizer\n",
        "\n",
        "\n",
        "Dictionary-based tokenizer is an alogirithm the read through the sentence character by character.  If it found sequences of characters match with a vocabulary in the pre-defined dictionary, it maps sequences of characters as a token.\n",
        "https://www.cs.ait.ac.th/~mdailey/papers/Choochart-Wordseg.pdf\n",
        "\n",
        "\n",
        "```python\n",
        "\n",
        "dictionary = Set[\"ฉัน\", \"ชอบ\", \"รถไฟ\", \"รถ\", \"รด\", \"น่ำ\", \"ต้น\", \"ไม้\", \"ต้นไม้\", \" \"]\n",
        "\n",
        "\n",
        "Dictionary_Tokenizer(dictionary:Set[str])\n",
        "\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HCU16osIdCCn",
        "colab_type": "text"
      },
      "source": [
        "#### 1.1 Longest matching (LM)\n",
        "\n",
        "Longest matching is an algorithm to split words from a sentence by considering logest vocab first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_79P-TYdCCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dictionary = set([\"ฉัน\", \"ชอบ\", \"รถไฟ\", \"รถ\", \"รด\", \"น่ำ\", \"ต้น\", \"ไม้\", \"ต้นไม้\", \" \", \"ฟ้า\"])\n",
        "\n",
        "def search_longest(term, dictionary):\n",
        "    term_length = len(term)\n",
        "    max_length = 0\n",
        "    for vocab in dictionary:\n",
        "        if term in vocab:\n",
        "            max_length = max(max_length, len(vocab))\n",
        "\n",
        "    return max_length == term_length\n",
        "\n",
        "def Dictionary_Tokenizer_LM_debug(sentence:str, dictionary: Set[str]):\n",
        "    buffer = \"\"\n",
        "    tokens = []\n",
        "    for char in sentence:\n",
        "        buffer += char\n",
        "        print(\"buffer\", buffer)\n",
        "        if search_longest(buffer, dictionary) == True:\n",
        "            print(\"select this token: {}\".format(buffer))\n",
        "            tokens.append(buffer)\n",
        "            buffer = \"\"\n",
        "            print(\"clear the buffer.\")\n",
        "            print(\"\")\n",
        "    return tokens\n",
        "\n",
        "def Dictionary_Tokenizer_LM(sentence:str, dictionary: Set[str]):\n",
        "    buffer = \"\"\n",
        "    tokens = []\n",
        "    for char in sentence:\n",
        "        buffer += char\n",
        "        if search_longest(buffer, dictionary) == True:\n",
        "            tokens.append(buffer)\n",
        "            buffer = \"\"\n",
        "    return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uiG8uoH-dCCq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "outputId": "d307936d-62a9-4de0-f3f3-17fa4ccf656c"
      },
      "source": [
        "Dictionary_Tokenizer_LM_debug(\"ฉันชอบ รถไฟ\", dictionary)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "buffer ฉ\n",
            "buffer ฉั\n",
            "buffer ฉัน\n",
            "select this token: ฉัน\n",
            "clear the buffer.\n",
            "\n",
            "buffer ช\n",
            "buffer ชอ\n",
            "buffer ชอบ\n",
            "select this token: ชอบ\n",
            "clear the buffer.\n",
            "\n",
            "buffer  \n",
            "select this token:  \n",
            "clear the buffer.\n",
            "\n",
            "buffer ร\n",
            "buffer รถ\n",
            "buffer รถไ\n",
            "buffer รถไฟ\n",
            "select this token: รถไฟ\n",
            "clear the buffer.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ฉัน', 'ชอบ', ' ', 'รถไฟ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CmJ61VwhdCCt",
        "colab_type": "text"
      },
      "source": [
        "#### __Question 1:__ Create your own dictionary to tokenize the following sentences that can tokenize all the words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jT-KUu8cdCCu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sentences = [\n",
        "    \"กระทรวงคมนาคมและการสื่อสารกาตาร์ จัดงาน Qatar Information Technology Exhibition and Conference (QITCOM 2019)\",\n",
        "    \"ณ กรุงโดฮา รัฐกาตาร์\",\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8O-E5g9dCCx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fill the vocabulary to dictionary_lm\n",
        "\n",
        "dictionary_lm = set([\n",
        "    \" \",\n",
        "    \"Qatar\",\n",
        "    \"Information\",\n",
        "    \"กระทรวงคมนาคมและการสื่อสาร\",\n",
        "    \"กาตาร์\",\n",
        "    # add more vocab\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsgVKpWRdCCz",
        "colab_type": "text"
      },
      "source": [
        "__Test:__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FdpDZalldCCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_Dictionary_Tokenizer_LM(dictionary_lm):\n",
        "    \n",
        "    tokens_list = [ Dictionary_Tokenizer_LM(sentence, dictionary_lm) for sentence in test_sentences]\n",
        "    character_count_expect = sum([len(sentence) for sentence in test_sentences])\n",
        "    character_count_actual = 0\n",
        "    for tokens in tokens_list:\n",
        "        character_count_actual += sum(map(lambda token : len(token),tokens))\n",
        "\n",
        "    if(character_count_actual == character_count_expect):\n",
        "        print(\"✅ Test succeed. 😁\")\n",
        "        \n",
        "        print(\"\\n tokens_list: \", tokens_list)\n",
        "    else:\n",
        "        print(\"Test failed. 😭\\n\")\n",
        "        \n",
        "        print(\"test_sentences\", test_sentences)\n",
        "        print(\"tokens_list\", tokens_list)\n",
        "        \n",
        "        print('')\n",
        "        print(\"character_count_actual != character_count_expect\")\n",
        "        print(\"{} != {}\".format(character_count_actual, character_count_expect))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4tRq3IpdCC2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "58065ac4-451c-492b-d30a-1f4533d2fc4a"
      },
      "source": [
        "# Run this block to test the code\n",
        "test_Dictionary_Tokenizer_LM(dictionary_lm)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test failed. 😭\n",
            "\n",
            "test_sentences ['กระทรวงคมนาคมและการสื่อสารกาตาร์ จัดงาน Qatar Information Technology Exhibition and Conference (QITCOM 2019)', 'ณ กรุงโดฮา รัฐกาตาร์']\n",
            "tokens_list [['กระทรวงคมนาคมและการสื่อสาร', 'กาตาร์', ' '], []]\n",
            "\n",
            "character_count_actual != character_count_expect\n",
            "33 != 128\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F5zHDQdMdCC4",
        "colab_type": "text"
      },
      "source": [
        "__Solution:__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHjOtKjCdCC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dictionary_lm = set([\n",
        "    \"Qatar\",\n",
        "    \"Information\",\n",
        "    \"กระทรวงคมนาคมและการสื่อสาร\",\n",
        "    \"กาตาร์\",\n",
        "    \"ณ\",\n",
        "    \"กรุงโดฮา\",\n",
        "    \"รัฐ\",\n",
        "    \" \",\n",
        "    \"จัดงาน\",\n",
        "    \"(\",\n",
        "    \")\",\n",
        "    \"QITCOM\", \"2019\",\n",
        "    \"Qatar\",\n",
        "    \"Information\",\n",
        "    \"Technology\",\n",
        "    \"Exhibition\",\n",
        "    \"and\",\n",
        "    \"Conference\"\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSo3E6jUdCC7",
        "colab_type": "code",
        "colab": {},
        "outputId": "ce39274a-533c-4903-9918-8c720db2ada8"
      },
      "source": [
        "test_Dictionary_Tokenizer_LM(dictionary_lm)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "✅ Test succeed. 😁\n",
            "\n",
            " tokens_list:  [['กระทรวงคมนาคมและการสื่อสาร', 'กาตาร์', ' ', 'จัดงาน', ' ', 'Qatar', ' ', 'Information', ' ', 'Technology', ' ', 'Exhibition', ' ', 'and', ' ', 'Conference', ' ', '(', 'QITCOM', ' ', '2019', ')'], ['ณ', ' ', 'กรุงโดฮา', ' ', 'รัฐ', 'กาตาร์']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xmgTnZOAdCC9",
        "colab_type": "text"
      },
      "source": [
        "#### 1.2 Maximal matching (MM)\n",
        "\n",
        "\n",
        "Unlike Longest Matching, Maximal matching is an algorithm to split words from a sentence in which it prefers minumum number of tokens to be splited.\n",
        "\n",
        "\n",
        "```python\n",
        "\n",
        "dictionary = set([\"รถ\", \"รถไฟ\", \"ฟ้า\", \"ไฟฟ้า\", \"ใต้ดิน\"])\n",
        "\n",
        "\n",
        "sentence = \"รถไฟฟ้าใต้ดิน\"\n",
        "\n",
        "Possible_segments(sentence) ->\n",
        "[\"รถไฟ\", \"ฟ้า\", \"ใต้ดิน\"]\n",
        "[\"รถ\", \"ไฟฟ้า\", \"ใต้ดิน\"]\n",
        "[\"รถไฟฟ้า\", \"ใต้ดิน\"]\n",
        "\n",
        "\n",
        "selected_segment = [\"รถไฟฟ้า\", \"ใต้ดิน\"]\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JqZpRdwydCC-",
        "colab_type": "text"
      },
      "source": [
        "#### PyThaiNLP's Tokenizer (newmm)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9M10q16kdCC-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pythainlp.tokenize import word_tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjTgmlK7dCDA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_sentence = \"กระทรวงคมนาคมและการสื่อสารกาตาร์ จัดงาน Qatar Information Technology Exhibition and Conference (QITCOM 2019)\"\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOJQUzw9dCDD",
        "colab_type": "code",
        "colab": {},
        "outputId": "f8f9f9e4-4828-43b4-c91e-b04ce494dee8"
      },
      "source": [
        "tokens = word_tokenize(test_sentence, engine=\"newmm\")\n",
        "print(tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['กระทรวงคมนาคม', 'และ', 'การสื่อสาร', 'กาตาร์', ' ', 'จัดงาน', ' ', 'Qatar', ' ', 'Information', ' ', 'Technology', ' ', 'Exhibition', ' ', 'and', ' ', 'Conference', ' ', '(', 'QITCOM', ' ', '2019', ')']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "djZBuOFWdCDG",
        "colab_type": "text"
      },
      "source": [
        "__Try out:__\n",
        "\n",
        "2.1 Try adding your own sentence.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVjwwTCsdCDH",
        "colab_type": "code",
        "colab": {},
        "outputId": "46e917e3-5b75-4fd5-c290-5856e5a74881"
      },
      "source": [
        "# Example sentence\n",
        "print(word_tokenize(\"ฉันอยุ๋ที่ สถาบันบัณฑิตพัฒนบริหารศาสตร์\", engine=\"newmm\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ฉัน', 'อยุ๋', 'ที่', ' ', 'สถาบันบัณฑิตพัฒนบริหารศาสตร์']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L7Q0Oy07dCDJ",
        "colab_type": "code",
        "colab": {},
        "outputId": "7e8cb6ea-e722-4dcb-abe6-bb1a090263ea"
      },
      "source": [
        "# Enter you own setnence\n",
        "print(word_tokenize(\" \", engine=\"newmm\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f-PpDtCdCDL",
        "colab_type": "text"
      },
      "source": [
        "2.2 Try adding your own sentence with misspelling.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNSPhJ7gdCDM",
        "colab_type": "code",
        "colab": {},
        "outputId": "315c98f1-81e7-4e7a-aab6-a4d026de40f2"
      },
      "source": [
        "# Example sentence with misspelling words\n",
        "print(word_tokenize(\"ฉันอยุ๋ที่ สถาบันบัณฑิตพัฒนบยริหารศาสตร์\", engine=\"newmm\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ฉัน', 'อยุ๋', 'ที่', ' ', 'สถาบัน', 'บัณฑิต', 'พัฒน', 'บย', 'ริ', 'หาร', 'ศาสตร์']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkjmqVUOdCDN",
        "colab_type": "code",
        "colab": {},
        "outputId": "c1d62cea-6faa-491f-a36d-13d00f993986"
      },
      "source": [
        "# Enter you own setnence\n",
        "print(word_tokenize(\" \", engine=\"newmm\"))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "blpcwX4IdCDQ",
        "colab_type": "text"
      },
      "source": [
        "#### __Question 2:__ Add your own custom dictionary for `newmm` tokenizer to tokenize the into the following tokens:\n",
        "\n",
        "```\n",
        "\n",
        "\"วันที่ 22 ต.ค. เอเอฟพีรายงานว่า สมเด็จพระจักรพรรดินารุฮิโตะ ทรงเข้าพระราชพิธีบรมราชาภิเษก เป็นสมเด็จพระจักรพรรดิแห่งญี่ปุ่นโดยสมบูรณ์แล้ววันนี้ ที่พระราชวังหลวงในกรุงโตเกียว\",\n",
        "\n",
        "```\n",
        "\n",
        "Result with the default dictionary:\n",
        "\n",
        "```\n",
        "['วันที่', ' ', '22', ' ', 'ต.ค.', ' ', 'เอเอฟพี', 'รายงาน', 'ว่า', ' ', 'สมเด็จ', 'พระ', 'จักรพรรดิ', 'นา', 'รุ', 'ฮิ', 'โตะ', ' ', 'ทรง', 'เข้า', 'พระราชพิธี', 'บรมราชาภิเษก', ' ', 'เป็น', 'สมเด็จ', 'พระ', 'จักรพรรดิ', 'แห่ง', 'ญี่ปุ่น', 'โดย', 'สมบูรณ์', 'แล้ว', 'วันนี้', ' ', 'ที่', 'พระราชวัง', 'หลวง', 'ใน', 'กรุง', 'โตเกียว']\n",
        "```\n",
        "\n",
        "Expectation:\n",
        "```\n",
        "['วันที่', ' ', '22', ' ', 'ต.ค.', ' ', 'เอเอฟพี', 'รายงาน', 'ว่า', ' ', 'สมเด็จพระจักรพรรดิ', 'นารุฮิโตะ', ' ', 'ทรง', 'เข้า', 'พระราชพิธี', 'บรมราชาภิเษก', ' ', 'เป็น', 'สมเด็จพระจักรพรรดิ', 'แห่ง', 'ญี่ปุ่น', 'โดย', 'สมบูรณ์', 'แล้ว', 'วันนี้', ' ', 'ที่', 'พระราชวัง', 'หลวง', 'ใน', 'กรุงโตเกียว']\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VASYtZq9dCDR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pythainlp.tokenize.trie import Trie\n",
        "from pythainlp.corpus import thai_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oye-sEuXdCDS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_from_news = \"\"\"วันที่ 22 ต.ค. เอเอฟพีรายงานว่า สมเด็จพระจักรพรรดินารุฮิโตะ ทรงเข้าพระราชพิธีบรมราชาภิเษก เป็นสมเด็จพระจักรพรรดิแห่งญี่ปุ่นโดยสมบูรณ์แล้ววันนี้ ที่พระราชวังหลวงในกรุงโตเกียว\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "feTxEFsxdCDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Add vocab in this list\n",
        "custom_vocab = [\n",
        "    \n",
        "    \n",
        "]\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWFsGmh2dCDW",
        "colab_type": "text"
      },
      "source": [
        "__Test:__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M12ugrhEdCDW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_tokenize_japan_news(custom_vocab):\n",
        "    expect = ['วันที่', ' ', '22', ' ', 'ต.ค.', ' ', 'เอเอฟพี', 'รายงาน', 'ว่า', ' ',\n",
        "              'สมเด็จพระจักรพรรดิ', 'นารุฮิโตะ', ' ', 'ทรง', 'เข้า', 'พระราชพิธี', 'บรมราชาภิเษก',\n",
        "              ' ', 'เป็น', 'สมเด็จพระจักรพรรดิ', 'แห่ง', 'ญี่ปุ่น', 'โดย', 'สมบูรณ์', 'แล้ว', 'วันนี้',\n",
        "              ' ', 'ที่', 'พระราชวัง', 'หลวง', 'ใน', 'กรุงโตเกียว']\n",
        "    \n",
        "    custom_dict_trie = Trie( list(thai_words()) + custom_vocab)\n",
        "\n",
        "    actual = word_tokenize(text_from_news, custom_dict=custom_dict_trie, engine=\"newmm\")\n",
        "    \n",
        "    \n",
        "   \n",
        "    if actual == expect:\n",
        "        print(\"✅ Test succeed. 😁\")\n",
        "    else:\n",
        "        print(\"❌ Test failed. 😭\")\n",
        "        print(\"\\nYour result    :\\n\\n\", \"|\".join(actual))\n",
        "        print(\"\\nExtected result:\\n\\n\", \"|\".join(expect))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xg7jdiA9dCDY",
        "colab_type": "code",
        "colab": {},
        "outputId": "2696b7cb-c89e-4fcc-d708-20fc5a9a1847"
      },
      "source": [
        "test_tokenize_japan_news(custom_vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "❌ Test failed. 😭\n",
            "\n",
            "Your result    :\n",
            "\n",
            " วันที่| |22| |ต.ค.| |เอเอฟพี|รายงาน|ว่า| |สมเด็จ|พระ|จักรพรรดิ|นา|รุ|ฮิ|โตะ| |ทรง|เข้า|พระราชพิธี|บรมราชาภิเษก| |เป็น|สมเด็จ|พระ|จักรพรรดิ|แห่ง|ญี่ปุ่น|โดย|สมบูรณ์|แล้ว|วันนี้| |ที่|พระราชวัง|หลวง|ใน|กรุง|โตเกียว\n",
            "\n",
            "Extected result:\n",
            "\n",
            " วันที่| |22| |ต.ค.| |เอเอฟพี|รายงาน|ว่า| |สมเด็จพระจักรพรรดิ|นารุฮิโตะ| |ทรง|เข้า|พระราชพิธี|บรมราชาภิเษก| |เป็น|สมเด็จพระจักรพรรดิ|แห่ง|ญี่ปุ่น|โดย|สมบูรณ์|แล้ว|วันนี้| |ที่|พระราชวัง|หลวง|ใน|กรุงโตเกียว\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-XYVeK3TdCDa",
        "colab_type": "text"
      },
      "source": [
        "__Solution:__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgqw4IKkdCDb",
        "colab_type": "code",
        "colab": {},
        "outputId": "1614ce41-ba69-42fc-e3cc-f76d3440f032"
      },
      "source": [
        "# Add vocab\n",
        "custom_vocab = [\n",
        "    \"สมเด็จพระจักรพรรดิ\",\n",
        "    \"กรุงโตเกียว\",\n",
        "    \"นารุฮิโตะ\"\n",
        "]\n",
        "\n",
        "test_tokenize_japan_news(custom_vocab)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "✅ Test succeed. 😁\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": false,
        "id": "alP5sF__dCDe",
        "colab_type": "text"
      },
      "source": [
        "### Learning-based tokenizer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqYSqnlgdCDf",
        "colab_type": "text"
      },
      "source": [
        "Tokenizer is a Machine Learning model and train on supervised daataset (labeled dataset).\n",
        "\n",
        "\n",
        "For example, one tokenizer of PyThaiNLP (`attacut`) uses Convolutional-neural Network to read the whole text and then determind word boundaries.\n",
        "\n",
        "![attacut](https://github.com/korakot/pythainlp_workshop/blob/master/notebooks/images/attacut.png?raw=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aGy5lXUydCDf",
        "colab_type": "text"
      },
      "source": [
        "#### attacut"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ficBJ7DTdCDg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q attacut"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NhVeWIMZdCDi",
        "colab_type": "code",
        "colab": {},
        "outputId": "c91da7db-538e-4d1e-df8e-488ce6f37240"
      },
      "source": [
        "test_sentence = \"กระทรวงคมนาคมและการสื่อสารกาตาร์ จัดงาน Qatar Information Technology Exhibition and Conference (QITCOM 2019)\"\n",
        "\n",
        "tokens = word_tokenize(test_sentence, engine=\"attacut\")\n",
        "print(tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['กระทรวงคมนาคม', 'และ', 'การสื่อสารกาตาร์', ' ', 'จัด', 'งาน', ' ', 'Qatar', ' ', 'Information', ' ', 'Technology', ' ', 'Exhibition', ' ', 'and', ' ', 'Conference', ' ', '(', 'QITCOM', ' ', '2019', ')']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fcn3UDaLdCDk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XAddG_UsdCDm",
        "colab_type": "code",
        "colab": {},
        "outputId": "7ee42e89-86a3-40da-cefb-ff6f9c7772c8"
      },
      "source": [
        "test_sentence = \"ฉันอยุ๋ที่ สถาบันบัณฑิตพัฒนบริหารศาสตร์\"\n",
        "\n",
        "tokens = word_tokenize(test_sentence, engine=\"attacut\")\n",
        "print(tokens)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['ฉัน', 'อยุ๋', 'ที่', ' ', 'สถาบันบัณฑิตพัฒนบริหารศาสตร์']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Fkps71WdCDo",
        "colab_type": "text"
      },
      "source": [
        "__Try out:__ Try adding your own sentence.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXa100KNdCDp",
        "colab_type": "code",
        "colab": {},
        "outputId": "48623a80-92ba-47c6-c77a-a5621bf20e27"
      },
      "source": [
        "# Enter you own setnence\n",
        "print(word_tokenize(\" \", engine=\"attacut\"))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[' ']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "toc-hr-collapsed": false,
        "id": "wYtc1sbvdCDq",
        "colab_type": "text"
      },
      "source": [
        "## 2. Part of speech and Named Entity Recognition Tagging\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o1-MSoWgdCDr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q sklearn_crfsuite"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8eRAxyrdCDt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pythainlp.tag.named_entity import ThaiNameTagger\n",
        "\n",
        "tagger = ThaiNameTagger()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-Nv83L3dCDw",
        "colab_type": "text"
      },
      "source": [
        "#### Named Entitiy Regcognition (NER) Tags:\n",
        "\n",
        "|       Tags       |      Examples                       |\n",
        "|------------------|-------------------------------------|\n",
        "        DATE       |   1 ตุลาคม 2012                      |\n",
        "        EMAIL      |   hr@mycompany.com                  |    \n",
        "        LAW        |  พรบ.คุ้มครองผู้บริโภค                   |\n",
        "        LEN        |       80 กิโลเมตร                    |     \n",
        "      LOCATION     |  กรุงเทพ, ประเทศจีน, เอเวอเรสต์        | \n",
        "        MONEY      |   2,190 ล้านบาท                      |\n",
        "    ORGANIZATION   |  คณะอักษรศาสตร์ จุฬาลงกรณ์มหาวิทยาลัย     |\n",
        "       PERCENT     |   95.34%, 10เปอร์เซนต์                |\n",
        "       PERSON      |   อรรถพล ธำรงรัตนฤทธิ์                 |\n",
        "        PHONE      |   +6611-123-1123                    |\n",
        "         TIME      |      14:20 น, เวลาเที่ยงตรง           |\n",
        "          URL      |     mycompany.com                   |\n",
        "         ZIP       |     รหัสไปรณีย์ 21210                  |"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lin9_degdCDw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence = \"วันนี้ วันที่ 1 ตุลาคม ได้ไปงานเปิดบ้าน ที่มหาวิทยาลัยธรรมศาสตร์\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMBecyjJdCDz",
        "colab_type": "code",
        "colab": {},
        "outputId": "c47c93e1-3725-4ebc-ebc0-3aeeed27d8dc"
      },
      "source": [
        "tagger.get_ner(sentence, pos=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('วันนี้', 'B-DATE'),\n",
              " (' ', 'O'),\n",
              " ('วันที่', 'O'),\n",
              " (' ', 'O'),\n",
              " ('1', 'B-DATE'),\n",
              " (' ', 'I-DATE'),\n",
              " ('ตุลาคม', 'I-DATE'),\n",
              " (' ', 'O'),\n",
              " ('ได้', 'O'),\n",
              " ('ไป', 'O'),\n",
              " ('งาน', 'O'),\n",
              " ('เปิด', 'O'),\n",
              " ('บ้าน', 'O'),\n",
              " (' ', 'O'),\n",
              " ('ที่', 'O'),\n",
              " ('มหาวิทยาลัยธรรมศาสตร์', 'B-LOCATION')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62htot2RdCD0",
        "colab_type": "code",
        "colab": {},
        "outputId": "e637dec2-0181-4557-b18d-dfe47ab53f51"
      },
      "source": [
        "tagger.get_ner(sentence, pos=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('วันนี้', 'NOUN', 'B-DATE'),\n",
              " (' ', 'PUNCT', 'O'),\n",
              " ('วันที่', 'NOUN', 'O'),\n",
              " (' ', 'PUNCT', 'O'),\n",
              " ('1', 'NUM', 'B-DATE'),\n",
              " (' ', 'PUNCT', 'I-DATE'),\n",
              " ('ตุลาคม', 'NOUN', 'I-DATE'),\n",
              " (' ', 'PUNCT', 'O'),\n",
              " ('ได้', 'AUX', 'O'),\n",
              " ('ไป', 'VERB', 'O'),\n",
              " ('งาน', 'NOUN', 'O'),\n",
              " ('เปิด', 'VERB', 'O'),\n",
              " ('บ้าน', 'NOUN', 'O'),\n",
              " (' ', 'PUNCT', 'O'),\n",
              " ('ที่', 'SCONJ', 'O'),\n",
              " ('มหาวิทยาลัยธรรมศาสตร์', 'NOUN', 'B-LOCATION')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agCxSj_odCD2",
        "colab_type": "text"
      },
      "source": [
        "#### __Question 3:__ From the following setentences how many types of named-entity appear in the sentence\n",
        "\n",
        "\n",
        "```text\n",
        "เมื่อวันที่ ๓๑ ตุลาคม ๒๕๖๒ เวลา 13:00 น. ตามเวลาประเทศไทย\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gt1u-YjydCD2",
        "colab_type": "code",
        "colab": {},
        "outputId": "04e50696-5a10-4fd4-d664-ba3cc7c8badd"
      },
      "source": [
        "tagger.get_ner(\"เมื่อวันที่ ๓๑ ตุลาคม ๒๕๖๒ เวลา 13:00 น. ตามเวลาประเทศไทย\", pos=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('เมื่อ', 'O'),\n",
              " ('วันที่', 'O'),\n",
              " (' ', 'O'),\n",
              " ('๓๑', 'B-DATE'),\n",
              " (' ', 'I-DATE'),\n",
              " ('ตุลาคม', 'I-DATE'),\n",
              " (' ', 'I-DATE'),\n",
              " ('๒๕๖๒', 'I-DATE'),\n",
              " (' ', 'O'),\n",
              " ('เวลา', 'O'),\n",
              " (' ', 'O'),\n",
              " ('13', 'B-TIME'),\n",
              " (':', 'I-TIME'),\n",
              " ('00', 'I-TIME'),\n",
              " (' ', 'I-TIME'),\n",
              " ('น.', 'I-TIME'),\n",
              " (' ', 'O'),\n",
              " ('ตามเวลา', 'O'),\n",
              " ('ประเทศ', 'O'),\n",
              " ('ไทย', 'B-LOCATION')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGGfbqF4dCD4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VrqforwGdCD7",
        "colab_type": "text"
      },
      "source": [
        "#### __Question 4:__ From the following setentences how many types of named-entity appear in the sentence\n",
        "\n",
        "Reference: https://www.khaosod.co.th/around-the-world-news/news_2993136\n",
        "\n",
        "```text\n",
        "วันที่ 22 ต.ค. เอเอฟพีรายงานว่า สมเด็จพระจักรพรรดินารุฮิโตะ ทรงเข้าพระราชพิธีบรมราชาภิเษก\n",
        "เป็นสมเด็จพระจักรพรรดิแห่งญี่ปุ่นโดยสมบูรณ์แล้ววันนี้ ที่พระราชวังหลวงในกรุงโตเกียว\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0y2fZmNdCD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UqRf8S-pdCD-",
        "colab_type": "code",
        "colab": {},
        "outputId": "a0283882-1b9d-42d0-ccc9-51c11b1599f5"
      },
      "source": [
        "# Try out\n",
        "tagger.get_ner(\"วันที่ 22 ต.ค. เอเอฟพีรายงานว่า สมเด็จพระจักรพรรดินารุฮิโตะ ทรงเข้าพระราชพิธีบรมราชาภิเษก เป็นสมเด็จพระจักรพรรดิแห่งญี่ปุ่นโดยสมบูรณ์แล้ววันนี้ ที่พระราชวังหลวงในกรุงโตเกียว\", pos=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('วันที่', 'O'),\n",
              " (' ', 'O'),\n",
              " ('22', 'B-DATE'),\n",
              " (' ', 'I-DATE'),\n",
              " ('ต.ค.', 'I-DATE'),\n",
              " (' ', 'O'),\n",
              " ('เอเอฟพี', 'B-ORGANIZATION'),\n",
              " ('รายงาน', 'O'),\n",
              " ('ว่า', 'O'),\n",
              " (' ', 'O'),\n",
              " ('สมเด็จ', 'B-PERSON'),\n",
              " ('พระ', 'I-PERSON'),\n",
              " ('จักรพรรดิ', 'I-PERSON'),\n",
              " ('นา', 'I-PERSON'),\n",
              " ('รุ', 'I-PERSON'),\n",
              " ('ฮิ', 'I-PERSON'),\n",
              " ('โตะ', 'I-PERSON'),\n",
              " (' ', 'O'),\n",
              " ('ทรง', 'O'),\n",
              " ('เข้า', 'O'),\n",
              " ('พระราชพิธี', 'O'),\n",
              " ('บรมราชาภิเษก', 'O'),\n",
              " (' ', 'O'),\n",
              " ('เป็น', 'O'),\n",
              " ('สมเด็จ', 'O'),\n",
              " ('พระ', 'O'),\n",
              " ('จักรพรรดิ', 'O'),\n",
              " ('แห่ง', 'O'),\n",
              " ('ญี่ปุ่น', 'B-LOCATION'),\n",
              " ('โดย', 'O'),\n",
              " ('สมบูรณ์', 'O'),\n",
              " ('แล้ว', 'O'),\n",
              " ('วันนี้', 'B-DATE'),\n",
              " (' ', 'O'),\n",
              " ('ที่', 'O'),\n",
              " ('พระราชวัง', 'B-LOCATION'),\n",
              " ('หลวง', 'I-LOCATION'),\n",
              " ('ใน', 'O'),\n",
              " ('กรุง', 'B-LOCATION'),\n",
              " ('โตเกียว', 'I-LOCATION')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NGlkEIMedCD_",
        "colab_type": "text"
      },
      "source": [
        "#### __Question 5:__ From the following setentences how many types of named-entity appear in the sentence\n",
        "\n",
        "Reference: [link](http://www.arts.chula.ac.th/ling/blog/tag/%E0%B8%AD%E0%B8%A3%E0%B8%A3%E0%B8%96%E0%B8%9E%E0%B8%A5-%E0%B8%98%E0%B8%B3%E0%B8%A3%E0%B8%87%E0%B8%A3%E0%B8%B1%E0%B8%95%E0%B8%99%E0%B8%A4%E0%B8%97%E0%B8%98%E0%B8%B4%E0%B9%8C/)\n",
        "\n",
        "```text\n",
        "คณะอักษรศาสตร์ จุฬาลงกรณ์มหาวิทยาลัย ขอเชิญชวนผู้สนใจเข้าร่วมฟังบรรยายพิเศษ\n",
        "เรื่อง “การวิเคราะห์ความสัมพันธ์ภายในปริจเฉทแบบอัตโนมัติด้วยการจำแนกคำเชื่อม”\n",
        "โดย ดร.อรรถพล ธำรงรัตนฤทธิ์\n",
        "\n",
        "วันศุกร์ที่ 17 พฤศจิกายน 2560 เวลา 13.30-14.30 น.\n",
        "เป็นต้นไป ณ ห้อง 401/5 อาคารมหาจักรีสิรินธร คณะอักษรศาสตร์ จุฬาลงกรณ์มหาวิทยาลัย\n",
        "\n",
        "สอบถามรายละเอียดเพิ่มเติมได้ที่ 0-2218-4692\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYo5gOgGdCEA",
        "colab_type": "code",
        "colab": {},
        "outputId": "b6879c0c-2b36-4bef-e50c-f376220d0396"
      },
      "source": [
        "text = \"\"\"คณะอักษรศาสตร์ จุฬาลงกรณ์มหาวิทยาลัย\n",
        "ขอเชิญชวนผู้สนใจเข้าร่วมฟังบรรยายพิเศษ \n",
        "เรื่อง “การวิเคราะห์ความสัมพันธ์ภายในปริจเฉทแบบอัตโนมัติด้วยการจำแนกคำเชื่อม”\n",
        "โดย ดร.อรรถพล ธำรงรัตนฤทธิ์\n",
        "วันศุกร์ที่ 17 พฤศจิกายน 2560 เวลา 13.30-14.30 น. เป็นต้นไป ณ ห้อง 401/5 อาคารมหาจักรีสิรินธร คณะอักษรศาสตร์ จุฬาลงกรณ์มหาวิทยาลัย\n",
        "สอบถามรายละเอียดเพิ่มเติมได้ที่ 0-2218-4692\n",
        "\"\"\"\n",
        "\n",
        "tagger.get_ner(text, pos=False)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('คณะอักษรศาสตร์', 'B-ORGANIZATION'),\n",
              " (' ', 'O'),\n",
              " ('จุฬาลงกรณ์', 'B-ORGANIZATION'),\n",
              " ('มหาวิทยาลัย', 'I-ORGANIZATION'),\n",
              " ('\\n', 'O'),\n",
              " ('ขอ', 'O'),\n",
              " ('เชิญชวน', 'O'),\n",
              " ('ผู้', 'O'),\n",
              " ('สนใจ', 'O'),\n",
              " ('เข้าร่วม', 'O'),\n",
              " ('ฟัง', 'O'),\n",
              " ('บรรยาย', 'O'),\n",
              " ('พิเศษ', 'O'),\n",
              " (' ', 'O'),\n",
              " ('\\n', 'O'),\n",
              " ('เรื่อง', 'O'),\n",
              " (' ', 'O'),\n",
              " ('“', 'O'),\n",
              " ('การ', 'O'),\n",
              " ('วิเคราะห์', 'O'),\n",
              " ('ความสัมพันธ์', 'O'),\n",
              " ('ภายใน', 'O'),\n",
              " ('ปริ', 'O'),\n",
              " ('จ', 'O'),\n",
              " ('เฉท', 'O'),\n",
              " ('แบบ', 'O'),\n",
              " ('อัตโนมัติ', 'O'),\n",
              " ('ด้วย', 'O'),\n",
              " ('การจำแนก', 'O'),\n",
              " ('คำเชื่อม', 'O'),\n",
              " ('”', 'O'),\n",
              " ('\\n', 'O'),\n",
              " ('โดย', 'O'),\n",
              " (' ', 'O'),\n",
              " ('ดร.', 'B-PERSON'),\n",
              " ('อรรถ', 'I-PERSON'),\n",
              " ('พล', 'I-PERSON'),\n",
              " (' ', 'I-PERSON'),\n",
              " ('ธำรง', 'I-PERSON'),\n",
              " ('รัตน', 'I-PERSON'),\n",
              " ('ฤทธิ์', 'I-PERSON'),\n",
              " ('\\n', 'I-PERSON'),\n",
              " ('วัน', 'I-PERSON'),\n",
              " ('ศุกร์', 'I-PERSON'),\n",
              " ('ที่', 'O'),\n",
              " (' ', 'O'),\n",
              " ('17', 'B-DATE'),\n",
              " (' ', 'I-DATE'),\n",
              " ('พฤศจิกายน', 'I-DATE'),\n",
              " (' ', 'I-DATE'),\n",
              " ('2560', 'I-DATE'),\n",
              " (' ', 'O'),\n",
              " ('เวลา', 'O'),\n",
              " (' ', 'O'),\n",
              " ('13.30', 'B-TIME'),\n",
              " ('-', 'I-TIME'),\n",
              " ('14.30', 'I-TIME'),\n",
              " (' ', 'I-TIME'),\n",
              " ('น.', 'I-TIME'),\n",
              " (' ', 'O'),\n",
              " ('เป็นต้นไป', 'O'),\n",
              " (' ', 'O'),\n",
              " ('ณ', 'O'),\n",
              " (' ', 'O'),\n",
              " ('ห้อง', 'O'),\n",
              " (' ', 'O'),\n",
              " ('401', 'O'),\n",
              " ('/', 'O'),\n",
              " ('5', 'O'),\n",
              " (' ', 'O'),\n",
              " ('อาคาร', 'B-LOCATION'),\n",
              " ('มหา', 'I-LOCATION'),\n",
              " ('จักรี', 'I-LOCATION'),\n",
              " ('สิรินธร', 'I-LOCATION'),\n",
              " (' ', 'O'),\n",
              " ('คณะอักษรศาสตร์', 'O'),\n",
              " (' ', 'O'),\n",
              " ('จุฬาลงกรณ์', 'B-ORGANIZATION'),\n",
              " ('มหาวิทยาลัย', 'I-ORGANIZATION'),\n",
              " ('\\n', 'O'),\n",
              " ('สอบถาม', 'O'),\n",
              " ('รายละเอียด', 'O'),\n",
              " ('เพิ่มเติม', 'O'),\n",
              " ('ได้ที่', 'O'),\n",
              " (' ', 'O'),\n",
              " ('0', 'B-PHONE'),\n",
              " ('-', 'I-PHONE'),\n",
              " ('2218', 'I-PHONE'),\n",
              " ('-', 'I-PHONE'),\n",
              " ('4692', 'I-PHONE'),\n",
              " ('\\n', 'I-PHONE')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NK3rLhsrdCED",
        "colab_type": "text"
      },
      "source": [
        "#### Part of Speech (POS) Tags:\n",
        "\n",
        "\n",
        "Reference: [PUD Tags](https://universaldependencies.org/u/pos/all.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNrC5tYwdCED",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "|  Abbreviation |      Part-of-Speech tag    |            Examples             |       \n",
        "|---------------|----------------------------|---------------------------------|\n",
        "| ADJ           |  Adjective                 |    ใหม่, พิเศษ , ก่อน, มาก, สูง     |   \n",
        "| ADP           |  Adposition                |   แม้, ว่า, เมื่อ, ของ, สำหรับ       |   \n",
        "| ADV           |  Adverb                    |   ก่อน, ก็, เล็กน้อย, เลย, สุด       |   \n",
        "| AUX           |  Auxiliary                 |   เป็น, ใช่, คือ, คล้าย             |   \n",
        "| CCONJ         |  Coordinating conjunction  |   แต่, และ, หรือ                  |        \n",
        "| DET           |  Determiner                |   นี้, นั้น, ทั้ง, เพียง, (หนึ่ง)คน      |   \n",
        "| INTJ          |  Interjection              |   อุ้ย, โอ้ย                       |   \n",
        "| NOUN          |  Noun                      |   กำมือ, พวก, สนาม, กีฬา, บัญชี     |   \n",
        "| NUM           |  Numeral                   |   5,000, 103.7, 2004, หนึ่ง, ร้อย  |   \n",
        "| PART          |  Particle                  |   มา ขึ้น ไม่ ได้ เข้า               |      \n",
        "| PRON          |  Pronoun                   |   เรา, เขา, ตัวเอง, ใคร, เธอ     |   \n",
        "| PROPN         |  Proper noun               |   โอบามา, แคปิตอลฮิล, จีโอพี, ไมเคิล |   \n",
        "| PUNCT         |  Punctuation               |   (, ), \", ', :                 |    \n",
        "| SCONJ         |  Subordinating conjunction |    หาก, เพ่ราะว่า, ถ้า             |   \n",
        "| VERB          |  Verb                      |   เปิด, ให้, ใช้, เผชิญ, อ่าน        |\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqe_2wv-dCEE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pythainlp.tag import pos_tag"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoHmyaV0dCEF",
        "colab_type": "code",
        "colab": {},
        "outputId": "364c433c-9349-4fdc-de9a-059e48726917"
      },
      "source": [
        "\n",
        "sentence = \"ฉันไปเดินในสวนสาธารณะ\"\n",
        "tokens = word_tokenize(sentence, keep_whitespace=False)\n",
        "pos_tag(tokens, corpus=\"pud\", engine=\"perceptron\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ฉัน', 'PRON'),\n",
              " ('ไป', 'VERB'),\n",
              " ('เดิน', 'VERB'),\n",
              " ('ใน', 'ADP'),\n",
              " ('สวนสาธารณะ', 'NOUN')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "miJKobw1dCEI",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "```\n",
        "Explaination:\n",
        "\n",
        "PRON = Pronoun \n",
        "\n",
        "VERB = Verb\n",
        "\n",
        "ADP = Adposition\n",
        "\n",
        "NOUN = Noun\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4Xa68kOdCEI",
        "colab_type": "code",
        "colab": {},
        "outputId": "8b6c48d0-c46c-408e-a199-8494ca2a8238"
      },
      "source": [
        "\n",
        "sentence = \"ฉันไปเดินในสวนสาธารณะ\"\n",
        "tokens = word_tokenize(sentence, keep_whitespace=False)\n",
        "pos_tag(tokens, corpus=\"orchid\", engine=\"perceptron\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('ฉัน', 'PPRS'),\n",
              " ('ไป', 'VACT'),\n",
              " ('เดิน', 'VACT'),\n",
              " ('ใน', 'RPRE'),\n",
              " ('สวนสาธารณะ', 'NCMN')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9A3ZUYnMdCEK",
        "colab_type": "text"
      },
      "source": [
        "```\n",
        "Explaination:\n",
        "\n",
        "PPRS = Personal pronoun \n",
        "\n",
        "VACT = Active verb\n",
        "\n",
        "RPRE = Preposition\n",
        "\n",
        "NCMN = Common noun\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uznIH98dCEL",
        "colab_type": "text"
      },
      "source": [
        "#### __Question 6:__ From the following setentences what are the POS tags (based on UD)\n",
        "\n",
        "\n",
        "```text\n",
        "หมา และ แมว กำลังกิน อาหาร\n",
        "```\n",
        "\n",
        "\n",
        "Hint: Here is the list of POS tags of this sentence.\n",
        "\n",
        "- NOUN = Noun\n",
        "- CCONJ = Coordinating Conjunction\n",
        "- VERB = Active Verb\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mRWMoplzdCEL",
        "colab_type": "code",
        "colab": {},
        "outputId": "217a92d9-b4a4-483d-95b4-301b9c91805a"
      },
      "source": [
        "# Run this block to see the result\n",
        "\n",
        "sentence = \"หมาและแมวกำลังกินอาหาร\"\n",
        "tokens = word_tokenize(sentence, keep_whitespace=False)\n",
        "pos_tag(tokens, corpus=\"ud\", engine=\"perceptron\")\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('หมา', 'NOUN'),\n",
              " ('และ', 'CCONJ'),\n",
              " ('แมว', 'NOUN'),\n",
              " ('กำลังกิน', 'VERB'),\n",
              " ('อาหาร', 'NOUN')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nvLRzpOdCEN",
        "colab_type": "text"
      },
      "source": [
        "#### __Question 7:__ From the following setentences what are the POS tags (based on Orchid)\n",
        "\n",
        "\n",
        "```text\n",
        "หมา และ แมว กำลังกิน อาหาร\n",
        "```\n",
        "\n",
        "Hint: Here is the list of POS tags of this sentence.\n",
        "\n",
        "- NCMN = Common Noun\n",
        "- JCRG = Coordinating Conjunction\n",
        "- VACT = Active Verb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YCPgwliIdCEN",
        "colab_type": "code",
        "colab": {},
        "outputId": "4075ae55-62b8-4e34-e44a-809cc71e6d42"
      },
      "source": [
        "# Run this block to see the result\n",
        "\n",
        "sentence = \"หมาและแมวกำลังกินอาหาร\"\n",
        "tokens = word_tokenize(sentence, keep_whitespace=False)\n",
        "pos_tag(tokens, corpus=\"orchid\", engine=\"perceptron\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('หมา', 'NCMN'),\n",
              " ('และ', 'JCRG'),\n",
              " ('แมว', 'NCMN'),\n",
              " ('กำลังกิน', 'VACT'),\n",
              " ('อาหาร', 'NCMN')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYkg6VTAdCEP",
        "colab_type": "text"
      },
      "source": [
        "## 3. Spell checking\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Pthc3PFdCEQ",
        "colab_type": "text"
      },
      "source": [
        "### 3.1 PyThaiNLP's spell checker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDJn_ijcdCEQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pythainlp.spell import correct"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFP4XeJ5dCES",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mispelled_words = [\n",
        "    \"โรงพยาบาน\",\n",
        "    \"สวัสดิ\",\n",
        "    \"ประธาราธิปดี\",\n",
        "    \"สัปปะรด\",\n",
        "    \"สังเกตุ\",\n",
        "    \"เหตการณ์\",\n",
        "    \"อนุญาติ\",\n",
        "    \"ฝักไฝ่\",\n",
        "    \"นายกรัญมนตี\"\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4pJBox4dCET",
        "colab_type": "code",
        "colab": {},
        "outputId": "c636851f-e2f6-437c-f83a-52b4e4a4d224"
      },
      "source": [
        "for word in mispelled_words:\n",
        "    print(\"{} -> {}\".format(word, correct(word)))\n",
        "    print(\"\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "โรงพยาบาน -> โรงพยาบาล\n",
            "\n",
            "สวัสดิ -> สวัสดี\n",
            "\n",
            "ประธาราธิปดี -> ประธานาธิบดี\n",
            "\n",
            "สัปปะรด -> สับปะรด\n",
            "\n",
            "สังเกตุ -> สังเกต\n",
            "\n",
            "เหตการณ์ -> เหตุการณ์\n",
            "\n",
            "อนุญาติ -> อนุญาต\n",
            "\n",
            "ฝักไฝ่ -> ฝักใฝ่\n",
            "\n",
            "นายกรัญมนตี -> นายกรัฐมนตรี\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKNUmGRfdCEU",
        "colab_type": "text"
      },
      "source": [
        "__Try out:__ Put any mispelling words and correct them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DN-yStWdCEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "correct(\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7CQfZN5dCEW",
        "colab_type": "text"
      },
      "source": [
        "## 4. Utility functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bz20hXJ4dCEW",
        "colab_type": "text"
      },
      "source": [
        "### 4.1 Thai digits and currency Conversion\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFr1uvPkdCEX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pythainlp.util import (\n",
        "    thai_digit_to_arabic_digit,\n",
        "    arabic_digit_to_thai_digit,\n",
        "    bahttext,\n",
        "    digit_to_text,\n",
        "    thaiword_to_num)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "veW6IxltdCEY",
        "colab_type": "code",
        "colab": {},
        "outputId": "05d1bbc7-3587-45e5-9097-c581d19d751a"
      },
      "source": [
        "thai_digit_to_arabic_digit(\"เมื่อวันที่ ๓๑ ตุลาคม ๒๕๖๒ เวลา ๑๓:๐๐ น. ตามเวลาประเทศไทย\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'เมื่อวันที่ 31 ตุลาคม 2562 เวลา 13:00 น. ตามเวลาประเทศไทย'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lHlVCVbdCEa",
        "colab_type": "code",
        "colab": {},
        "outputId": "7f86dbb8-f5fe-4f85-f902-bca62ffa2403"
      },
      "source": [
        "arabic_digit_to_thai_digit(\"เมื่อวันที่ 31 ตุลาคม2562 เวลา 13:00 น. ตามเวลาประเทศไทย\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'เมื่อวันที่ ๓๑ ตุลาคม๒๕๖๒ เวลา ๑๓:๐๐ น. ตามเวลาประเทศไทย'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRQ4v3rRdCEc",
        "colab_type": "code",
        "colab": {},
        "outputId": "13b8bb89-fd12-468e-bcb2-8b46a8c6b4c6"
      },
      "source": [
        "bahttext(1234.24)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'หนึ่งพันสองร้อยสามสิบสี่บาทยี่สิบสี่สตางค์'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFWhAMO9dCEe",
        "colab_type": "code",
        "colab": {},
        "outputId": "70172fe5-5bac-46a9-a7f4-5d7cb52f2299"
      },
      "source": [
        "bahttext(21)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ยี่สิบเอ็ดบาทถ้วน'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFU8b2CidCEf",
        "colab_type": "code",
        "colab": {},
        "outputId": "d19f5de8-164b-4406-a861-914873c4a2b1"
      },
      "source": [
        "bahttext(240000000000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'สองแสนสี่หมื่นล้านบาทถ้วน'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VWJ-00FtdCEg",
        "colab_type": "code",
        "colab": {},
        "outputId": "717a3edd-e798-4b4b-9e23-967e4ef1fbf0"
      },
      "source": [
        "thaiword_to_num(\"หนึ่งร้อย\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGGLibyMdCEh",
        "colab_type": "code",
        "colab": {},
        "outputId": "0d768479-b61f-46a3-cf8b-48dfa5c1f716"
      },
      "source": [
        "digit_to_text(\"๓ ร้อยล้าน\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'สาม ร้อยล้าน'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4czXmaMdCEj",
        "colab_type": "code",
        "colab": {},
        "outputId": "498c69d9-cf5c-4e6c-f7d4-4bc8134f9613"
      },
      "source": [
        "digit_to_text(\"๓๑\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'สามหนึ่ง'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVmE2-QcdCEl",
        "colab_type": "code",
        "colab": {},
        "outputId": "07b0e77b-9560-4030-e84d-ac9c6741fbc4"
      },
      "source": [
        "thaiword_to_num(\"หนึ่งพันหนึ่ง\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SREyVYJddCEn",
        "colab_type": "code",
        "colab": {},
        "outputId": "a1a85f3f-b587-4904-88f2-a8bd198032c2"
      },
      "source": [
        "thaiword_to_num(\"หนึ่งล้านหกสิบเอ็ด\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000061"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTBFaZJJdCEo",
        "colab_type": "code",
        "colab": {},
        "outputId": "c696793a-3c4b-4557-b855-4dd5c5b2fd3a"
      },
      "source": [
        "thaiword_to_num(\"พันล้าน\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQsGtS0tdCEq",
        "colab_type": "text"
      },
      "source": [
        "#### __Question 8 :__ Given a text representing an amont money, convert into number.\n",
        "\n",
        "```\n",
        "เพื่อเพิ่มมูลค่าการค้าซึ่งปัจจุบันมีประมาณ ๑๒,๕๐๐ ล้านดอลลาร์สหรัฐ ให้ทวีขึ้นเป็น ๓ หมื่นล้าน\n",
        "```\n",
        "->\n",
        "```\n",
        "เพื่อเพิ่มมูลค่าการค้าซึ่งปัจจุบันมีประมาณ 12,500 ล้านดอลลาร์สหรัฐ ให้ทวีขึ้นเป็น 3 หมื่นล้าน\n",
        "\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiWHIGGEdCEq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text_with_thai_digits = \"เพื่อเพิ่มมูลค่าการค้าซึ่งปัจจุบันมีประมาณ ๑๒,๕๐๐ ล้านดอลลาร์สหรัฐ ให้ทวีขึ้นเป็น ๓ หมื่นล้าน\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYPtRi3pdCEr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(text):\n",
        "    splits = text.split(\" \")\n",
        "    \n",
        "    for index, split in enumerate(splits):\n",
        "        \n",
        "        if re.search(r\"[๐-๙]\", split):\n",
        "            print(\"\\nselcted split: \", split)\n",
        "            ## Modify the following line to convert from thai digits to arabic\n",
        "\n",
        "            splits[index] = split\n",
        "            \n",
        "            ##--------------------- ##\n",
        "            print(\"convert to: \", splits[index])\n",
        "    \n",
        "    return \" \".join(splits)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrVnG502dCEt",
        "colab_type": "code",
        "colab": {},
        "outputId": "a8df30ad-6611-4737-f994-7299f25bb012"
      },
      "source": [
        "convert(text_with_thai_digits)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "selcted split:  ๑๒,๕๐๐\n",
            "convert to:  ๑๒,๕๐๐\n",
            "\n",
            "selcted split:  ๓\n",
            "convert to:  ๓\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'เพื่อเพิ่มมูลค่าการค้าซึ่งปัจจุบันมีประมาณ ๑๒,๕๐๐ ล้านดอลลาร์สหรัฐ ให้ทวีขึ้นเป็น ๓ หมื่นล้าน'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2uTItrKdCEu",
        "colab_type": "text"
      },
      "source": [
        "__Test:__ Given a list of sentences, please return only Thai sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4fFB3-rdCEv",
        "colab_type": "code",
        "colab": {},
        "outputId": "61becbba-d995-4cfd-e398-f6567eae638f"
      },
      "source": [
        "def test_convert_thai_digits(convert):\n",
        "    expect = \"เพื่อเพิ่มมูลค่าการค้าซึ่งปัจจุบันมีประมาณ 12,500 ล้านดอลลาร์สหรัฐ ให้ทวีขึ้นเป็น 3 หมื่นล้าน\"\n",
        "    actual = convert(text_with_thai_digits)\n",
        "\n",
        "    if actual == expect:\n",
        "        print(\"✅ Test succeed. 😁\")\n",
        "    else:\n",
        "        print(\"❌ Test failed. 😭\")\n",
        "        print(\"The actual results:\", actual)\n",
        "\n",
        "test_convert_thai_digits(convert)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "selcted split:  ๑๒,๕๐๐\n",
            "convert to:  ๑๒,๕๐๐\n",
            "\n",
            "selcted split:  ๓\n",
            "convert to:  ๓\n",
            "❌ Test failed. 😭\n",
            "The actual results: เพื่อเพิ่มมูลค่าการค้าซึ่งปัจจุบันมีประมาณ ๑๒,๕๐๐ ล้านดอลลาร์สหรัฐ ให้ทวีขึ้นเป็น ๓ หมื่นล้าน\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1R0mdTYjdCEw",
        "colab_type": "text"
      },
      "source": [
        "__Solution:__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1at31RndCEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert(text):\n",
        "    splits = text.split(\" \")\n",
        "    \n",
        "    for index, split in enumerate(splits):\n",
        "        \n",
        "        if re.search(r\"[๐-๙]\", split):\n",
        "            print(\"\\nselcted split: \", split)\n",
        "            ## Write the code to convert\n",
        "\n",
        "            splits[index] = thai_digit_to_arabic_digit(split)\n",
        "            \n",
        "            \n",
        "            print(\"convert to: \", splits[index])\n",
        "\n",
        "    return \" \".join(splits)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ji5J62zJdCEy",
        "colab_type": "code",
        "colab": {},
        "outputId": "27304981-c83c-4d05-aefc-038a9aa42a9a"
      },
      "source": [
        "test_convert_thai_digits(convert)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "selcted split:  ๑๒,๕๐๐\n",
            "convert to:  12,500\n",
            "\n",
            "selcted split:  ๓\n",
            "convert to:  3\n",
            "✅ Test succeed. 😁\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W62wyBakdCEz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDaHyLEwdCE0",
        "colab_type": "text"
      },
      "source": [
        "### 4.2 Thai Word count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZWfz6dIdCE0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pythainlp.util import countthai\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLkOneJmdCE2",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Count percentage of Thai chacters in a text.\n",
        "\n",
        "```python\n",
        " countthai(text:str) -> percentage:float\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7OoPKZ-TdCE3",
        "colab_type": "code",
        "colab": {},
        "outputId": "49955d70-3925-43c6-c517-ea8097a39195"
      },
      "source": [
        "countthai(\"Hello world.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iqDexyU4dCE4",
        "colab_type": "code",
        "colab": {},
        "outputId": "9f216182-597b-4596-97b7-36bddd6985dc"
      },
      "source": [
        "countthai(\"สวัสดี ฉันชอบนั่งรถไฟ\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaA75gKwdCE5",
        "colab_type": "code",
        "colab": {},
        "outputId": "3e160ac0-aafe-4f70-8eda-544e062ea192"
      },
      "source": [
        "countthai(\"สวัสดี Jane Doe\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "46.15384615384615"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPZ8Pj3odCE6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AY48u8z7dCE8",
        "colab_type": "text"
      },
      "source": [
        "#### __Question 9:__ Given a list of sentences, please return only Thai sentences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0k-NkTqdCE9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "en_th_sentences = [\n",
        "    \"มันจะมีอะไรที่ทำให้ ผิดพลาดได้ล่ะ?\",\n",
        "    \"สวัสดี... ...ดิ๊ก\",\n",
        "    \"# Just to get a glimpse beyond this illusion #\",\n",
        "    \"# I was soaring ever higher #\",\n",
        "    \"# but I flew too high #\",\n",
        "    \"    ใช่\",\n",
        "    \"ใช่ เขาและแฟรงค์ และ แคส ถ้าขวดเหล้าเขา อยู่ในกระเป๋า\",\n",
        "    \"มันก็ดีที่เราได้คราวลีย์ มาอยู่ฝั่งเราถูกมั้ย?\",\n",
        "    \"คุณคราวลีย์ เรามีเรื่องต้องคุยกันเยอะเลย\",\n",
        "    \"เชิญนั่ง\",\n",
        "    \"== sync, corrected by elderman ==\",\n",
        "    \"# though my eyes could see, I still was a blind man #\",\n",
        "    \"# though my mind could think, I still was a madman #\",\n",
        "    \"ได้เห็นว่า พวกมันทั้งหมดมาตามล่าเขา\",\n",
        "    \"# I hear the voices when I'm dreaming #\",\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-QEVb62dCE-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_thai_sentence(sentence):\n",
        "\n",
        "    ## Write down the code, to return value True if the sentence is in Thai language\n",
        "    \n",
        "    \n",
        "    \n",
        "    ##\n",
        "    return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11rdBna6dCE_",
        "colab_type": "text"
      },
      "source": [
        "__Test:__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WlCh_khkdCE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "th_sentences = [\n",
        "    \"มันจะมีอะไรที่ทำให้ ผิดพลาดได้ล่ะ?\",\n",
        "    \"สวัสดี... ...ดิ๊ก\",\n",
        "    \"    ใช่\",\n",
        "    \"ใช่ เขาและแฟรงค์ และ แคส ถ้าขวดเหล้าเขา อยู่ในกระเป๋า\",\n",
        "    \"มันก็ดีที่เราได้คราวลีย์ มาอยู่ฝั่งเราถูกมั้ย?\",\n",
        "    \"คุณคราวลีย์ เรามีเรื่องต้องคุยกันเยอะเลย\",\n",
        "    \"เชิญนั่ง\",\n",
        "    \"ได้เห็นว่า พวกมันทั้งหมดมาตามล่าเขา\",\n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LOXQEQYQdCFA",
        "colab_type": "code",
        "colab": {},
        "outputId": "3777d85d-c861-48a8-93ca-fea879371aa6"
      },
      "source": [
        "actual = list(filter(test_thai_sentence, en_th_sentences))\n",
        "expect = th_sentences\n",
        "\n",
        "if actual == expect:\n",
        "    print(\"✅ Test succeed. 😁\")\n",
        "else:\n",
        "    print(\"❌ Test failed. 😭\")\n",
        "    print(\"The actual results:\", actual)\n",
        "    print(\"\\nThe expected sentences to be returned:\\n\")\n",
        "    for i, sentence in enumerate(th_sentences):\n",
        "        print(i+1, sentence)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "❌ Test failed. 😭\n",
            "The actual results: []\n",
            "\n",
            "The expected sentences to be returned:\n",
            "\n",
            "1 มันจะมีอะไรที่ทำให้ ผิดพลาดได้ล่ะ?\n",
            "2 สวัสดี... ...ดิ๊ก\n",
            "3     ใช่\n",
            "4 ใช่ เขาและแฟรงค์ และ แคส ถ้าขวดเหล้าเขา อยู่ในกระเป๋า\n",
            "5 มันก็ดีที่เราได้คราวลีย์ มาอยู่ฝั่งเราถูกมั้ย?\n",
            "6 คุณคราวลีย์ เรามีเรื่องต้องคุยกันเยอะเลย\n",
            "7 เชิญนั่ง\n",
            "8 ได้เห็นว่า พวกมันทั้งหมดมาตามล่าเขา\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYIZrf32dCFB",
        "colab_type": "text"
      },
      "source": [
        "__Solution:__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUq5ZZFJdCFC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def test_thai_sentence(sentence):\n",
        "\n",
        "    ## Write down the code, to return value True if the sentence is in Thai language\n",
        "    \n",
        "    if countthai(sentence)  >= 90.0:\n",
        "        return True\n",
        "    \n",
        "    ##\n",
        "    return False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSVGJnsbdCFD",
        "colab_type": "code",
        "colab": {},
        "outputId": "58c41e3c-6b39-4295-c1b5-ca768048087d"
      },
      "source": [
        "actual = list(filter(test_thai_sentence, en_th_sentences))\n",
        "expect = th_sentences\n",
        "\n",
        "if actual == expect:\n",
        "    print(\"✅ Test succeed. 😁\")\n",
        "else:\n",
        "    print(\"❌ Test failed. 😭\")\n",
        "    print(\"The actual results:\", actual)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "✅ Test succeed. 😁\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WP5qhl8kdCFE",
        "colab_type": "text"
      },
      "source": [
        "### 4.3 Data and time"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hSuVEn8dCFE",
        "colab_type": "text"
      },
      "source": [
        "This function uses Thai names and Thai Buddhist Era for these directives:\n",
        "\n",
        "- __%a__ - abbreviated weekday name (e.g. “จ”, “อ”, “พ”, “พฤ”, “ศ”, “ส”, “อา”)\n",
        "\n",
        "- __%A__ - full weekday name (e.g.“วันจันทร์”, “วันอังคาร”, “วันเสาร์”, “วันอาทิตย์”)\n",
        "\n",
        "- __%b__ - abbreviated month name (e.g.“ม.ค.”,”ก.พ.”,”มี.ค.”,”เม.ย.”,”พ.ค.”,”มิ.ย.”, “ธ.ค.”)\n",
        "\n",
        "- __%B__ - full month name (e.g. “มกราคม”, “กุมภาพันธ์”, “พฤศจิกายน”, “ธันวาคม”,)\n",
        "\n",
        "- __%y__ - year without century (e.g. “56”, “10”)\n",
        "\n",
        "- __%Y__ - year with century (e.g. “2556”, “2410”)\n",
        "\n",
        "- __%c__ - date and time representation (e.g. “พ 6 ต.ค. 01:40:00 2519”)\n",
        "\n",
        "- __%v__ - short date representation (e.g. ” 6-ม.ค.-2562”, “27-ก.พ.-2555”)\n",
        "\n",
        "- __%d__ - day (e.g. \"01\", \"07\", 10\", \"31\")\n",
        "\n",
        "- __%-d__ - day with no zero padding (e.g. \"1\", \"7\",10\", \"31\")\n",
        " \n",
        "- __%H__  - hour (e.g. \"01\", \"06\", \"23\")\n",
        "\n",
        "- __%-H__ - hour with no zero padding (e.g. \"1\", \"6\", \"23\"))\n",
        "\n",
        "- __%M__  - minute (e.g. \"1\", \"2\", \"11\", \"12\")\n",
        "\n",
        "- __%S__  - second (e.g. \"1\", \"2\", \"11\", \"12\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bA0orfsdCFF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from datetime import datetime\n",
        "from pythainlp.util import thai_strftime\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJt_6vPvdCFH",
        "colab_type": "code",
        "colab": {},
        "outputId": "dfa525a7-a83b-4863-820f-01245b03970c"
      },
      "source": [
        "# Print the current date in Thai format\n",
        "\n",
        "thai_strftime(datetime.now(), \"%d %B %Y\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'01 พฤศจิกายน 2562'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZvxDSw9dCFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qwqh8midCFK",
        "colab_type": "text"
      },
      "source": [
        "#### __Question 10:__ Given a date time object, return the datetime string in the following format\n",
        "\n",
        "\n",
        "```\n",
        "วันศุกร์ ที่ 1 พฤศจิกายน ปี พ.ศ. 2562 เวลา 11 นาฬิกา 30 นาที 10 วินาที\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bx5rRluVdCFL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "datetime_object_workshop_day = datetime(year=2019, month=11, day=1,hour=11,minute=30,second=10)\n",
        "\n",
        "def print_datetime_thai(datetime_object):\n",
        "    # Write down the format string.\n",
        "    fmt = \"\"\n",
        "    return thai_strftime(datetime_object, fmt)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcrXOGu7dCFM",
        "colab_type": "text"
      },
      "source": [
        "__Test:__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ATOHHhVPdCFM",
        "colab_type": "code",
        "colab": {},
        "outputId": "e4c69c8b-2457-4a42-c3df-08985b20fc49"
      },
      "source": [
        "def test_print_datetime_thai(fn):\n",
        "    expect = \"วันศุกร์ ที่ 1 พฤศจิกายน พ.ศ. 2562 เวลา 11 นาฬิกา 30 นาที 10 วินาที\"\n",
        "    actual = fn(datetime_object_workshop_day)\n",
        "\n",
        "    if actual == expect:\n",
        "        print(\"✅ Test succeed. 😁\\n\")\n",
        "        print(\"Your Result:\",expect)\n",
        "    else:\n",
        "        print(\"❌ Test failed. 😭\")\n",
        "        print(\"\\nYour result    :\", actual)\n",
        "        print(\"\\nExpected result:\", expect)\n",
        "\n",
        "test_print_datetime_thai(print_datetime_thai)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "❌ Test failed. 😭\n",
            "\n",
            "Your result    : \n",
            "\n",
            "Expected result: วันศุกร์ ที่ 1 พฤศจิกายน พ.ศ. 2562 เวลา 11 นาฬิกา 30 นาที 10 วินาที\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGSWxv-DdCFO",
        "colab_type": "text"
      },
      "source": [
        "__Solution:__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Mn9Pyp1dCFO",
        "colab_type": "code",
        "colab": {},
        "outputId": "3d54da7e-6b8b-474f-d42b-263b561592dc"
      },
      "source": [
        "def print_datetime_thai(datetime_object):\n",
        "    # Write down the format string.\n",
        "    fmt = \"%A ที่ %-d %B พ.ศ. %Y เวลา %H นาฬิกา %M นาที %S วินาที\"\n",
        "    return thai_strftime(datetime_object, fmt)\n",
        "\n",
        "test_print_datetime_thai(print_datetime_thai)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "✅ Test succeed. 😁\n",
            "\n",
            "Your Result: วันศุกร์ ที่ 1 พฤศจิกายน พ.ศ. 2562 เวลา 11 นาฬิกา 30 นาที 10 วินาที\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8V0SdzvdCFP",
        "colab_type": "text"
      },
      "source": [
        "__Without Thai strftime__"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGYTLpnzdCFQ",
        "colab_type": "code",
        "colab": {},
        "outputId": "2d80c310-dff3-4b6f-8e4f-04d6c279a693"
      },
      "source": [
        "datetime_object_workshop_day.strftime(\"%A ที่ %-d %B พ.ศ. %Y เวลา %H นาฬิกา %M นาที %S วินาที\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Friday ที่ 1 November พ.ศ. 2019 เวลา 11 นาฬิกา 30 นาที 10 วินาที'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    }
  ]
}